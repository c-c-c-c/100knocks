{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlRy0GRvaxKg"
   },
   "source": [
    "# <center>Transformer from scratch２：モデルの学習</center>\n",
    "## <center>最終更新日(超未完成版)：2021.5/8</center>\n",
    "\n",
    "自己アテンションに基づくTransformerアーキテクチャをtf.Kerasで実装するノートブックです。同じような内容は\n",
    "\n",
    "https://www.tensorflow.org/tutorials/text/transformer?hl=ja\n",
    "\n",
    "にあります。また、スクラッチ実装をしなくても多くのライブラリでは簡単にSelf-Attention層が利用できます。しかしちゃんとTransformerを理解したりTransformerベースのモデルを開発したいなら、スクラッチ実装の経験がないといけないと思いますので、勉強していきましょう！\n",
    "\n",
    "[参考文献]\n",
    "\n",
    "https://arxiv.org/pdf/1706.03762.pdf\n",
    "\n",
    "このノートブックでは学習の実装を扱います。\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "前回のノートブックでモデルの準備ができましたので、いよいよ訓練の実装を行い、本物のデータで訓練してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ga33C6o_bAlV"
   },
   "source": [
    "# 0. 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1cmoYucbbO3"
   },
   "source": [
    "## 0.1 実装したモジュール等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rp7vM1H6avAj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# configuration\n",
    "source_vocab_size = 100000\n",
    "max_seq_len = 100\n",
    "d_model = 512\n",
    "do_rate = 0.2\n",
    "d_ff = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNnoQj5RcvKU"
   },
   "source": [
    "utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foFPvsLpbHo5"
   },
   "outputs": [],
   "source": [
    "def positional_encoding_function(t, i, d):\n",
    "    theta = t / 10000**(2*(i//2)/d) + np.pi/2 * (i%2)\n",
    "    return np.sin(theta)\n",
    "\n",
    "def positional_encoding(T, d):\n",
    "    dd, TT = np.meshgrid(np.arange(d), np.arange(T))\n",
    "    encoding = positional_encoding_function(TT, dd, d)\n",
    "    encoding = encoding[np.newaxis,:,:]\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oogxtCEcmvB"
   },
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrv4Soovb0Sk"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, max_seq_len, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.pos_encoding = positional_encoding(max_seq_len, d_model)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_dtype = inputs.dtype\n",
    "        pos_encoding = self.pos_encoding\n",
    "        pos_encoding = tf.cast(pos_encoding, dtype=input_dtype)\n",
    "        inputs *= tf.math.sqrt(tf.cast(self.d_model, dtype=input_dtype))\n",
    "\n",
    "        return inputs + pos_encoding\n",
    "\n",
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, n_heads, d_model):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert self.d_model % self.n_heads == 0, 'n_headsはd_modelの因数'\n",
    "\n",
    "        self.d = self.d_model // self.n_heads\n",
    "\n",
    "        self.dense_q = layers.Dense(d_model, use_bias=False)\n",
    "        self.dense_k = layers.Dense(d_model, use_bias=False)\n",
    "        self.dense_v = layers.Dense(d_model, use_bias=False)\n",
    "        self.dense_o = layers.Dense(d_model, use_bias=False)\n",
    "\n",
    "    def call(self, x_q, x_k, x_v, mask):\n",
    "        \n",
    "        q = self.dense_q(x_q)\n",
    "        k = self.dense_k(x_k)\n",
    "        v = self.dense_v(x_v)\n",
    "\n",
    "        max_seq_len = tf.shape(k)[1]\n",
    "        \n",
    "        q = self.split_to_heads(q, max_seq_len)\n",
    "        k = self.split_to_heads(k, max_seq_len)\n",
    "        v = self.split_to_heads(v, max_seq_len)\n",
    "\n",
    "        logit = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "        d_k = tf.shape(k)[-1]\n",
    "        k_dtype = k.dtype\n",
    "        scale = 1/tf.math.sqrt(tf.cast(d_k, k_dtype))\n",
    "        logit *= scale\n",
    "\n",
    "        if mask is not None:\n",
    "            logit += mask*k_dtype.min\n",
    "        \n",
    "        attention_weight = tf.nn.softmax(logit, axis=-1)\n",
    "        attention_output = tf.einsum('nhst,nhtd->nshd', attention_weight, v)\n",
    "        attention_output = tf.reshape(attention_output, (-1, max_seq_len, self.n_heads*self.d))\n",
    "        attention_output = self.dense_o(attention_output)\n",
    "\n",
    "        return attention_output, attention_weight\n",
    "\n",
    "    def split_to_heads(self, x, max_seq_len):\n",
    "        x = tf.reshape(x, (-1, max_seq_len, self.n_heads, self.d))\n",
    "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        return x\n",
    "\n",
    "class MHSAModule(layers.Layer):\n",
    "    def __init__(self, source_vocab_size, max_seq_len, d_model, n_heads, do_rate):\n",
    "        super(MHSAModule, self).__init__()\n",
    "        self.mhsa = MultiHeadSelfAttention(n_heads, d_model)\n",
    "        self.dropout = layers.Dropout(do_rate)\n",
    "        self.add = layers.Add()\n",
    "        self.norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, training, mask):\n",
    "        x, att = self.mhsa(inputs, inputs, inputs, mask)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.add([x,inputs])\n",
    "        x = self.norm(x)\n",
    "        return x, att\n",
    "\n",
    "class PointWiseFeedForwardModule(layers.Layer):\n",
    "    def __init__(self, d_model, d_ff, do_rate):\n",
    "        super(PointWiseFeedForwardModule, self).__init__()\n",
    "        self.pwff_1 = layers.Dense(d_ff, activation='relu')\n",
    "        self.pwff_2 = layers.Dense(d_model)\n",
    "        self.dropout = layers.Dropout(do_rate)\n",
    "        self.add = layers.Add()\n",
    "        self.norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = self.pwff_1(inputs)\n",
    "        x = self.pwff_2(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.add([x,inputs])\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "class EncoderModule(layers.Layer):\n",
    "    def __init__(self, source_vocab_size, max_seq_len, d_model, n_heads, do_rate):\n",
    "        super(EncoderModule, self).__init__()\n",
    "        self.mhsa = MHSAModule(source_vocab_size, max_seq_len, d_model, n_heads, do_rate)\n",
    "        self.pwff = PointWiseFeedForwardModule(d_model, d_ff, do_rate)\n",
    "\n",
    "    def call(self, inputs, training, mask):\n",
    "        x, att = self.mhsa(inputs, mask, training)\n",
    "        x = self.pwff(x, training)\n",
    "        return x, att\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, n_layers, source_vocab_size, max_seq_len, d_model, n_heads, do_rate):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.source_vocab_size = source_vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.do_rate = do_rate\n",
    "        self.do = layers.Dropout(do_rate)\n",
    "        self.embedding = layers.Embedding(source_vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(max_seq_len, d_model)\n",
    "        self.mhsa_modules = [EncoderModule(source_vocab_size, max_seq_len, d_model, n_heads, do_rate) for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs, training, mask_enc):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.do(x)\n",
    "        attention_weights = []\n",
    "        for module in self.mhsa_modules:\n",
    "            x, att = module(x, training, mask_enc)\n",
    "            attention_weights.append(att)\n",
    "        return x, attention_weights\n",
    "\n",
    "class MHSAModuleDec(layers.Layer):\n",
    "    def __init__(self, source_vocab_size, max_seq_len, d_model, n_heads, do_rate):\n",
    "        super(MHSAModuleDec, self).__init__()\n",
    "        self.mhsa = MultiHeadSelfAttention(n_heads, d_model)\n",
    "        self.dropout = layers.Dropout(do_rate)\n",
    "        self.add = layers.Add()\n",
    "        self.norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, context, training, mask):\n",
    "        x, att = self.mhsa(inputs, context, context, mask)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.add([x,inputs])\n",
    "        x = self.norm(x)\n",
    "        return x, att\n",
    "\n",
    "class DecoderModule(layers.Layer):\n",
    "    def __init__(self, source_vocab_size, max_seq_len, d_model, n_heads, do_rate):\n",
    "        super(DecoderModule, self).__init__()\n",
    "        self.mhsa1 = MHSAModule(source_vocab_size, max_seq_len, d_model, n_heads, do_rate)\n",
    "        self.mhsa2 = MHSAModuleDec(source_vocab_size, max_seq_len, d_model, n_heads, do_rate)\n",
    "        self.pwff = PointWiseFeedForwardModule(d_model, d_ff, do_rate)\n",
    "\n",
    "    def call(self, inputs, enc_outputs, training, mask, mask_look_ahead):\n",
    "        x, att1 = self.mhsa1(inputs, training, mask)\n",
    "        x, att2 = self.mhsa2(inputs, enc_outputs, training, mask_look_ahead)\n",
    "        x = self.pwff(x, training)\n",
    "        return x, att1, att2\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, n_layers, target_vocab_size, max_seq_len, d_model, n_heads, do_rate):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.do_rate = do_rate\n",
    "        self.do = layers.Dropout(do_rate)\n",
    "        self.embedding = layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(max_seq_len, d_model)\n",
    "        self.mhsa_modules = [DecoderModule(source_vocab_size, max_seq_len, d_model, n_heads, do_rate) for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs, enc_outputs, training, mask_dec, mask_look_ahead):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.do(x)\n",
    "        attention_weights = []\n",
    "        for module in self.mhsa_modules:\n",
    "            x, att1, att2 = module(x, enc_outputs, training, mask_dec, mask_look_ahead)\n",
    "            attention_weights += [[att1, att2]]\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2H03q1IYcoqj"
   },
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vi1XeG0lceG6"
   },
   "outputs": [],
   "source": [
    "class Transformer(layers.Layer):\n",
    "    def __init__(self, n_layers, source_vocab_size, target_vocab_size, max_seq_len, d_model, n_heads, do_rate):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.do_rate = do_rate\n",
    "        self.encoder = Encoder(n_layers, source_vocab_size, max_seq_len, d_model, n_heads, do_rate)\n",
    "        self.decoder = Decoder(n_layers, target_vocab_size, max_seq_len, d_model, n_heads, do_rate)\n",
    "        self.classification = layers.Dense(target_vocab_size-1)\n",
    "\n",
    "    def call(self, enc_inputs, dec_inputs, mask_enc, mask_dec, mask_look_ahead, training=False):\n",
    "\n",
    "        enc_outputs, att_enc = self.encoder(enc_inputs, training=training, mask_enc=mask_enc)\n",
    "        dec_outputs, att_dec = self.decoder(dec_inputs, enc_outputs, training=training, mask_dec=mask_dec, mask_look_ahead=mask_look_ahead)\n",
    "        y = self.classification(dec_outputs)\n",
    "\n",
    "        return y, att_enc + att_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STHqif2IbgCb"
   },
   "source": [
    "## 0.2 データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21590,
     "status": "ok",
     "timestamp": 1620807203997,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "iVmNF25_bmO_",
    "outputId": "1fbfcee8-da14-4b7e-ce12-01b668a12683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49852,
     "status": "ok",
     "timestamp": 1620807249402,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "UzlW1xYebtGo",
    "outputId": "3c965c37-d1c4-486d-eb54-6c3767ee9543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-460\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  aptitude-common libcgi-fast-perl libcgi-pm-perl libclass-accessor-perl\n",
      "  libcwidget3v5 libencode-locale-perl libfcgi-perl libhtml-parser-perl\n",
      "  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n",
      "  libio-string-perl liblwp-mediatypes-perl libparse-debianchangelog-perl\n",
      "  libsigc++-2.0-0v5 libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
      "Suggested packages:\n",
      "  aptitude-doc-en | aptitude-doc apt-xapian-index debtags tasksel\n",
      "  libcwidget-dev libdata-dump-perl libhtml-template-perl libxml-simple-perl\n",
      "  libwww-perl xapian-tools\n",
      "The following NEW packages will be installed:\n",
      "  aptitude aptitude-common libcgi-fast-perl libcgi-pm-perl\n",
      "  libclass-accessor-perl libcwidget3v5 libencode-locale-perl libfcgi-perl\n",
      "  libhtml-parser-perl libhtml-tagset-perl libhttp-date-perl\n",
      "  libhttp-message-perl libio-html-perl libio-string-perl\n",
      "  liblwp-mediatypes-perl libparse-debianchangelog-perl libsigc++-2.0-0v5\n",
      "  libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
      "0 upgraded, 21 newly installed, 0 to remove and 34 not upgraded.\n",
      "Need to get 3,877 kB of archives.\n",
      "After this operation, 15.6 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude-common all 0.8.10-6ubuntu1 [1,014 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigc++-2.0-0v5 amd64 2.10.0-2 [10.9 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcwidget3v5 amd64 0.5.17-7 [286 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxapian30 amd64 1.4.5-1ubuntu0.1 [631 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude amd64 0.8.10-6ubuntu1 [1,269 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-pm-perl all 4.38-1 [185 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfcgi-perl amd64 0.78-2build1 [32.8 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-fast-perl all 1:2.13-1 [9,940 B]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-accessor-perl all 0.51-1 [21.2 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-string-perl all 1.08-3 [11.1 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparse-debianchangelog-perl all 1.2.0-12 [49.5 kB]\n",
      "Fetched 3,877 kB in 0s (21.8 MB/s)\n",
      "Selecting previously unselected package aptitude-common.\n",
      "(Reading database ... 160706 files and directories currently installed.)\n",
      "Preparing to unpack .../00-aptitude-common_0.8.10-6ubuntu1_all.deb ...\n",
      "Unpacking aptitude-common (0.8.10-6ubuntu1) ...\n",
      "Selecting previously unselected package libsigc++-2.0-0v5:amd64.\n",
      "Preparing to unpack .../01-libsigc++-2.0-0v5_2.10.0-2_amd64.deb ...\n",
      "Unpacking libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
      "Selecting previously unselected package libcwidget3v5:amd64.\n",
      "Preparing to unpack .../02-libcwidget3v5_0.5.17-7_amd64.deb ...\n",
      "Unpacking libcwidget3v5:amd64 (0.5.17-7) ...\n",
      "Selecting previously unselected package libxapian30:amd64.\n",
      "Preparing to unpack .../03-libxapian30_1.4.5-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
      "Selecting previously unselected package aptitude.\n",
      "Preparing to unpack .../04-aptitude_0.8.10-6ubuntu1_amd64.deb ...\n",
      "Unpacking aptitude (0.8.10-6ubuntu1) ...\n",
      "Selecting previously unselected package libhtml-tagset-perl.\n",
      "Preparing to unpack .../05-libhtml-tagset-perl_3.20-3_all.deb ...\n",
      "Unpacking libhtml-tagset-perl (3.20-3) ...\n",
      "Selecting previously unselected package liburi-perl.\n",
      "Preparing to unpack .../06-liburi-perl_1.73-1_all.deb ...\n",
      "Unpacking liburi-perl (1.73-1) ...\n",
      "Selecting previously unselected package libhtml-parser-perl.\n",
      "Preparing to unpack .../07-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n",
      "Unpacking libhtml-parser-perl (3.72-3build1) ...\n",
      "Selecting previously unselected package libcgi-pm-perl.\n",
      "Preparing to unpack .../08-libcgi-pm-perl_4.38-1_all.deb ...\n",
      "Unpacking libcgi-pm-perl (4.38-1) ...\n",
      "Selecting previously unselected package libfcgi-perl.\n",
      "Preparing to unpack .../09-libfcgi-perl_0.78-2build1_amd64.deb ...\n",
      "Unpacking libfcgi-perl (0.78-2build1) ...\n",
      "Selecting previously unselected package libcgi-fast-perl.\n",
      "Preparing to unpack .../10-libcgi-fast-perl_1%3a2.13-1_all.deb ...\n",
      "Unpacking libcgi-fast-perl (1:2.13-1) ...\n",
      "Selecting previously unselected package libsub-name-perl.\n",
      "Preparing to unpack .../11-libsub-name-perl_0.21-1build1_amd64.deb ...\n",
      "Unpacking libsub-name-perl (0.21-1build1) ...\n",
      "Selecting previously unselected package libclass-accessor-perl.\n",
      "Preparing to unpack .../12-libclass-accessor-perl_0.51-1_all.deb ...\n",
      "Unpacking libclass-accessor-perl (0.51-1) ...\n",
      "Selecting previously unselected package libencode-locale-perl.\n",
      "Preparing to unpack .../13-libencode-locale-perl_1.05-1_all.deb ...\n",
      "Unpacking libencode-locale-perl (1.05-1) ...\n",
      "Selecting previously unselected package libtimedate-perl.\n",
      "Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n",
      "Unpacking libtimedate-perl (2.3000-2) ...\n",
      "Selecting previously unselected package libhttp-date-perl.\n",
      "Preparing to unpack .../15-libhttp-date-perl_6.02-1_all.deb ...\n",
      "Unpacking libhttp-date-perl (6.02-1) ...\n",
      "Selecting previously unselected package libio-html-perl.\n",
      "Preparing to unpack .../16-libio-html-perl_1.001-1_all.deb ...\n",
      "Unpacking libio-html-perl (1.001-1) ...\n",
      "Selecting previously unselected package liblwp-mediatypes-perl.\n",
      "Preparing to unpack .../17-liblwp-mediatypes-perl_6.02-1_all.deb ...\n",
      "Unpacking liblwp-mediatypes-perl (6.02-1) ...\n",
      "Selecting previously unselected package libhttp-message-perl.\n",
      "Preparing to unpack .../18-libhttp-message-perl_6.14-1_all.deb ...\n",
      "Unpacking libhttp-message-perl (6.14-1) ...\n",
      "Selecting previously unselected package libio-string-perl.\n",
      "Preparing to unpack .../19-libio-string-perl_1.08-3_all.deb ...\n",
      "Unpacking libio-string-perl (1.08-3) ...\n",
      "Selecting previously unselected package libparse-debianchangelog-perl.\n",
      "Preparing to unpack .../20-libparse-debianchangelog-perl_1.2.0-12_all.deb ...\n",
      "Unpacking libparse-debianchangelog-perl (1.2.0-12) ...\n",
      "Setting up libhtml-tagset-perl (3.20-3) ...\n",
      "Setting up libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
      "Setting up libencode-locale-perl (1.05-1) ...\n",
      "Setting up libtimedate-perl (2.3000-2) ...\n",
      "Setting up libio-html-perl (1.001-1) ...\n",
      "Setting up aptitude-common (0.8.10-6ubuntu1) ...\n",
      "Setting up liblwp-mediatypes-perl (6.02-1) ...\n",
      "Setting up liburi-perl (1.73-1) ...\n",
      "Setting up libhtml-parser-perl (3.72-3build1) ...\n",
      "Setting up libcgi-pm-perl (4.38-1) ...\n",
      "Setting up libio-string-perl (1.08-3) ...\n",
      "Setting up libsub-name-perl (0.21-1build1) ...\n",
      "Setting up libfcgi-perl (0.78-2build1) ...\n",
      "Setting up libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
      "Setting up libclass-accessor-perl (0.51-1) ...\n",
      "Setting up libhttp-date-perl (6.02-1) ...\n",
      "Setting up libcgi-fast-perl (1:2.13-1) ...\n",
      "Setting up libparse-debianchangelog-perl (1.2.0-12) ...\n",
      "Setting up libhttp-message-perl (6.14-1) ...\n",
      "Setting up libcwidget3v5:amd64 (0.5.17-7) ...\n",
      "Setting up aptitude (0.8.10-6ubuntu1) ...\n",
      "update-alternatives: using /usr/bin/aptitude-curses to provide /usr/bin/aptitude (aptitude) in auto mode\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n",
      "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
      "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
      "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
      "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
      "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
      "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
      "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
      "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
      "The following NEW packages will be installed:\n",
      "  file libmagic-mgc{a} libmagic1{a} libmecab-dev libmecab2{a} mecab mecab-ipadic{a} mecab-ipadic-utf8 mecab-jumandic{a} mecab-jumandic-utf8{a} mecab-utils{a} \n",
      "The following packages will be REMOVED:\n",
      "  libnvidia-common-460{u} \n",
      "0 packages upgraded, 11 newly installed, 1 to remove and 34 not upgraded.\n",
      "Need to get 29.3 MB of archives. After unpacking 282 MB will be used.\n",
      "Get: 1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
      "Get: 2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
      "Get: 3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n",
      "Get: 4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n",
      "Get: 5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n",
      "Get: 6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n",
      "Get: 7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic-utf8 all 7.0-20130310-4 [16.2 MB]\n",
      "Get: 8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic all 7.0-20130310-4 [2,212 B]\n",
      "Get: 9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n",
      "Get: 10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n",
      "Get: 11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n",
      "Fetched 29.3 MB in 0s (59.7 MB/s)\n",
      "(Reading database ... 161165 files and directories currently installed.)\n",
      "Removing libnvidia-common-460 (460.73.01-0ubuntu1) ...\n",
      "Selecting previously unselected package libmagic-mgc.\n",
      "(Reading database ... 161160 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
      "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
      "Selecting previously unselected package libmagic1:amd64.\n",
      "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
      "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
      "Selecting previously unselected package file.\n",
      "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
      "Unpacking file (1:5.32-2ubuntu0.4) ...\n",
      "Selecting previously unselected package libmecab2:amd64.\n",
      "Preparing to unpack .../03-libmecab2_0.996-5_amd64.deb ...\n",
      "Unpacking libmecab2:amd64 (0.996-5) ...\n",
      "Selecting previously unselected package libmecab-dev.\n",
      "Preparing to unpack .../04-libmecab-dev_0.996-5_amd64.deb ...\n",
      "Unpacking libmecab-dev (0.996-5) ...\n",
      "Selecting previously unselected package mecab-utils.\n",
      "Preparing to unpack .../05-mecab-utils_0.996-5_amd64.deb ...\n",
      "Unpacking mecab-utils (0.996-5) ...\n",
      "Selecting previously unselected package mecab-jumandic-utf8.\n",
      "Preparing to unpack .../06-mecab-jumandic-utf8_7.0-20130310-4_all.deb ...\n",
      "Unpacking mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
      "Selecting previously unselected package mecab-jumandic.\n",
      "Preparing to unpack .../07-mecab-jumandic_7.0-20130310-4_all.deb ...\n",
      "Unpacking mecab-jumandic (7.0-20130310-4) ...\n",
      "Selecting previously unselected package mecab-ipadic.\n",
      "Preparing to unpack .../08-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n",
      "Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n",
      "Selecting previously unselected package mecab.\n",
      "Preparing to unpack .../09-mecab_0.996-5_amd64.deb ...\n",
      "Unpacking mecab (0.996-5) ...\n",
      "Selecting previously unselected package mecab-ipadic-utf8.\n",
      "Preparing to unpack .../10-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n",
      "Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
      "Setting up libmecab2:amd64 (0.996-5) ...\n",
      "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
      "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
      "Setting up mecab-utils (0.996-5) ...\n",
      "Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n",
      "Compiling IPA dictionary for Mecab.  This takes long time...\n",
      "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
      "emitting double-array: 100% |###########################################| \n",
      "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
      "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
      "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
      "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
      "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
      "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
      "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
      "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
      "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
      "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
      "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
      "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
      "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
      "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
      "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
      "Setting up libmecab-dev (0.996-5) ...\n",
      "Setting up file (1:5.32-2ubuntu0.4) ...\n",
      "Setting up mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
      "Compiling Juman dictionary for Mecab.\n",
      "reading /usr/share/mecab/dic/juman/unk.def ... 37\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading /usr/share/mecab/dic/juman/Noun.hukusi.csv ... 81\n",
      "reading /usr/share/mecab/dic/juman/Assert.csv ... 34\n",
      "reading /usr/share/mecab/dic/juman/Emoticon.csv ... 972\n",
      "reading /usr/share/mecab/dic/juman/Postp.csv ... 108\n",
      "reading /usr/share/mecab/dic/juman/Rengo.csv ... 1118\n",
      "reading /usr/share/mecab/dic/juman/Special.csv ... 158\n",
      "reading /usr/share/mecab/dic/juman/AuxV.csv ... 593\n",
      "reading /usr/share/mecab/dic/juman/Wikipedia.csv ... 167709\n",
      "reading /usr/share/mecab/dic/juman/Suffix.csv ... 2128\n",
      "reading /usr/share/mecab/dic/juman/Noun.keishiki.csv ... 8\n",
      "reading /usr/share/mecab/dic/juman/Auto.csv ... 18931\n",
      "reading /usr/share/mecab/dic/juman/Prefix.csv ... 90\n",
      "reading /usr/share/mecab/dic/juman/Noun.koyuu.csv ... 7964\n",
      "reading /usr/share/mecab/dic/juman/ContentW.csv ... 551145\n",
      "reading /usr/share/mecab/dic/juman/Noun.suusi.csv ... 49\n",
      "reading /usr/share/mecab/dic/juman/Demonstrative.csv ... 97\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading /usr/share/mecab/dic/juman/matrix.def ... 1876x1876\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
      "Compiling IPA dictionary for Mecab.  This takes long time...\n",
      "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
      "emitting double-array: 100% |###########################################| \n",
      "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
      "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
      "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
      "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
      "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
      "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
      "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
      "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
      "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
      "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
      "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
      "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
      "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
      "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
      "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
      "Setting up mecab (0.996-5) ...\n",
      "Compiling IPA dictionary for Mecab.  This takes long time...\n",
      "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
      "emitting double-array: 100% |###########################################| \n",
      "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
      "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
      "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
      "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
      "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
      "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
      "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
      "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
      "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
      "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
      "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
      "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
      "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
      "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
      "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
      "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "Setting up mecab-jumandic (7.0-20130310-4) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n",
      "                            \n",
      "Collecting mecab-python3==0.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/e9/bbf5fc790a2bedd96fbaf47a84afa060bfb0b3e0217e5f64b32bd4bbad69/mecab-python3-0.7.tar.gz (41kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: mecab-python3\n",
      "  Building wheel for mecab-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mecab-python3: filename=mecab_python3-0.7-cp37-cp37m-linux_x86_64.whl size=156580 sha256=d536244e3d7447f505848cfcc3c45f418464dbb7f9b863e5bcc2c9a1f361ddb5\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/07/3a/5f22ccc9f381f3bc01fa023202061cd1e0e9af855292f005dd\n",
      "Successfully built mecab-python3\n",
      "Installing collected packages: mecab-python3\n",
      "Successfully installed mecab-python3-0.7\n"
     ]
    }
   ],
   "source": [
    "!apt install aptitude\n",
    "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
    "!pip install mecab-python3==0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2994,
     "status": "ok",
     "timestamp": 1620807797052,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "c0zFqWcNbjPw",
    "outputId": "725f5322-99dc-48bf-c09c-1fc4219a89ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of input characters w/out pad: 3014\n",
      "num of output characters w/out pad: 3982\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import MeCab\n",
    "import re\n",
    "#from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_samples = 10000  # 訓練に使うサンプルの数。この中の１割をvalに使う\n",
    "\n",
    "text_path = '/content/drive/MyDrive/ml_datasets/jpn-eng/jpn.txt'\n",
    "\n",
    "with open(text_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "#input_text_sp = re.split('\\s', 'No way!'.replace('!', ''))\n",
    "#input_text_sp.append('!')\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "tagger = MeCab.Tagger('-Owakati')\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "\n",
    "    last_char = input_text[-1]\n",
    "    if last_char in {'.', '!', '?'}:\n",
    "        input_text_replaced = input_text.replace(last_char, '')\n",
    "        input_text_sp = re.split('\\s', input_text_replaced)\n",
    "        input_text_sp.append(last_char)\n",
    "    else:\n",
    "        input_text_sp = re.split('\\s', input_text)\n",
    "\n",
    "    for word in input_text_sp:\n",
    "        if word not in input_characters:\n",
    "            input_characters.add(word)\n",
    "    input_texts.append(input_text_sp)\n",
    "    \n",
    "    # '\\t'を出力文の開始記号SOS、'\\n'を終了記号EOSに使う\n",
    "    result = tagger.parse(target_text)\n",
    "    wakachi = result.split()\n",
    "    wakachi = ['\\t'] + wakachi + ['\\n']\n",
    "    for word in wakachi:\n",
    "        if word not in target_characters:\n",
    "            target_characters.add(word)\n",
    "    target_texts.append(wakachi)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "\n",
    "print('num of input characters w/out pad:', len(input_characters))\n",
    "print('num of output characters w/out pad:', len(target_characters))\n",
    "\n",
    "\n",
    "# padding記号も含めておく\n",
    "num_encoder_tokens = len(input_characters) + 1\n",
    "num_decoder_tokens = len(target_characters) + 1\n",
    "\n",
    "# ここはハイパーパラメータ化\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "max_seq_len = max(max_encoder_seq_length, max_decoder_seq_length)\n",
    "\n",
    "# padding記号を0にする\n",
    "input_token_index = dict(\n",
    "    [(char, i+1) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i+1) for i, char in enumerate(target_characters)])\n",
    " \n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_seq_len),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_seq_len),\n",
    "    dtype='float32')\n",
    "\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_seq_len, num_decoder_tokens-1),\n",
    "    dtype='float32')\n",
    " \n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t] = input_token_index[char]\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = target_token_index[char]\n",
    "        if t > 0:\n",
    "            # 次の文字予測なので、targetは2文字目から始める\n",
    "            # targetはpad記号を含まない(num_decoder_tokens-1)文字に対するone-hot\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]-1] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yE47OHaYpfuU"
   },
   "source": [
    "Padding記号も含めた後では"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1620807801381,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "odVBQGmBpXnA",
    "outputId": "c1e94c10-9b9a-4ca0-a6df-36b39028861e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_encoder_tokens 3015\n",
      "num_decoder_tokens 3983\n"
     ]
    }
   ],
   "source": [
    "print('num_encoder_tokens', num_encoder_tokens)\n",
    "print('num_decoder_tokens', num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7PWmQRuQSgd"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1068,
     "status": "ok",
     "timestamp": 1620807878524,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "gS2ygw_teB9j",
    "outputId": "2105e358-69d7-4b35-c394-92664151bd7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 996,
     "status": "ok",
     "timestamp": 1620807879245,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "5qOyTpe_eP2Q",
    "outputId": "b077fe90-af8c-4d10-9fcd-47036f1d9dd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 18)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1620807879642,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "IlOKyK_reSI1",
    "outputId": "0b009771-66b0-46b5-a5e2-a570b0b22c61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 18, 3982)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qulTiDwWvDO9"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QxYEtDXBr3ZW"
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true,y_pred):\n",
    "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred+1e-16), axis=-1)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 905,
     "status": "ok",
     "timestamp": 1620812743744,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "hpP8okRCu8SU",
    "outputId": "ecb3f8b1-a608-4f6e-928b-05503254ebdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 128,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_loss(decoder_target_data[:10,:,:],decoder_target_data[:10,:,:]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1521,
     "status": "ok",
     "timestamp": 1620812744950,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "DMJLaLO0uLR_",
    "outputId": "53fd1b59-f905-4701-e3bc-0e9462e0cd07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.344901"
      ]
     },
     "execution_count": 129,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_loss(decoder_target_data[:10,:,:],decoder_target_data[8:18,:,:]).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQnsljTTc7Yf"
   },
   "source": [
    "# 1. 訓練プロセスの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TegBO2Ppd3uo"
   },
   "source": [
    "## 1-1. マスクについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zkuu2eoUc-33"
   },
   "outputs": [],
   "source": [
    "encoder_mask_data = np.where(encoder_input_data!=0, 0, 1)\n",
    "encoder_mask_data = encoder_mask_data.astype('float32')\n",
    "encoder_mask_data = encoder_mask_data[:, np.newaxis, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1061,
     "status": "ok",
     "timestamp": 1620809723144,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "gCHvF8exeixN",
    "outputId": "1eb30bf1-a0c8-430f-ab15-5c835feb263b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_mask_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1053,
     "status": "ok",
     "timestamp": 1620809726904,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "cUCzcqSce7K8",
    "outputId": "5c859cb1-fd04-40cf-c4ce-a5a8d14177bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 216.,    6.,    0., ...,    0.,    0.,    0.],\n",
       "       [ 216.,    6.,    0., ...,    0.,    0.,    0.],\n",
       "       [ 247.,    6.,    0., ...,    0.,    0.,    0.],\n",
       "       ...,\n",
       "       [ 157., 3004., 1194., ...,    0.,    0.,    0.],\n",
       "       [ 157., 3004., 1194., ...,    0.,    0.,    0.],\n",
       "       [ 157., 3004., 1532., ...,    0.,    0.,    0.]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYXPjhjve79s"
   },
   "outputs": [],
   "source": [
    "decoder_mask_data = np.where(decoder_input_data!=0, 0, 1)\n",
    "decoder_mask_data = decoder_mask_data.astype('float32')\n",
    "decoder_mask_data = decoder_mask_data[:, np.newaxis, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1620809738024,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "deI4quM8fLk2",
    "outputId": "f5049829-c79c-4813-b96d-a88e586e3dfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_mask_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPiHcgLVvm6I"
   },
   "outputs": [],
   "source": [
    "look_ahead = 1.-np.tril(np.ones((max_seq_len,max_seq_len)))\n",
    "look_ahead = look_ahead[np.newaxis, np.newaxis, :, :]\n",
    "\n",
    "decoder_mask_look_ahead_data = np.clip(decoder_mask_data + look_ahead, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 943,
     "status": "ok",
     "timestamp": 1620809754907,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "9UDdYjSow0kW",
    "outputId": "7f02f7ed-9646-434b-a256-1d2fbaf3f4fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 1., 1., ..., 1., 1., 1.],\n",
       "         [0., 0., 1., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "         [0., 0., 1., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "         [0., 0., 1., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "         [0., 0., 1., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "         [0., 0., 1., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "         [0., 0., 1., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.],\n",
       "         [0., 0., 0., ..., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_mask_look_ahead_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1620799154035,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "ggdaIDqhfNvJ",
    "outputId": "11f750ef-b2ca-492d-aa0a-5acc1824e9db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 3.422e+03, 3.800e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 3.419e+03, 6.620e+02, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 3.660e+02, 3.800e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [1.000e+00, 1.034e+03, 3.899e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 1.034e+03, 9.190e+02, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 2.958e+03, 7.090e+02, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2154,
     "status": "ok",
     "timestamp": 1620813339862,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "7l0i8aLYfOjh",
    "outputId": "6999bb46-d527-4c03-99a6-38cb31b4974e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"trasnformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 18)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 18)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           [(None, 1, 1, 18)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           [(None, 1, 18, 18)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "transformer_16 (Transformer)    ((None, 18, 3982), [ 6495118     encoder_input[0][0]              \n",
      "                                                                 decoder_input[0][0]              \n",
      "                                                                 input_33[0][0]                   \n",
      "                                                                 input_33[0][0]                   \n",
      "                                                                 input_34[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,495,118\n",
      "Trainable params: 6,495,118\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_heads = 8\n",
    "n_layers = 2\n",
    "d_ff = 1024#2048\n",
    "d_model = 256\n",
    "do_rate = 0.2\n",
    "\n",
    "encoder_inputs = layers.Input(shape=(max_seq_len,), name='encoder_input')\n",
    "decoder_inputs = layers.Input(shape=(max_seq_len,), name='decoder_input')\n",
    "\n",
    "encoder_mask = layers.Input(shape=(1,1,max_seq_len))\n",
    "#decoder_mask = layers.Input(shape=(1,1,max_seq_len))\n",
    "decoder_look_ahead_mask = layers.Input(shape=(1,max_seq_len,max_seq_len))\n",
    "\n",
    "transformer = Transformer(n_layers, num_encoder_tokens, num_decoder_tokens, max_seq_len, d_model, n_heads, do_rate)\n",
    "y = transformer(encoder_inputs, decoder_inputs, mask_enc=encoder_mask, mask_dec=encoder_mask, mask_look_ahead=decoder_look_ahead_mask, training=True)\n",
    "\n",
    "transformer_model = tf.keras.models.Model(inputs=[encoder_inputs, decoder_inputs, encoder_mask, decoder_look_ahead_mask], outputs=y[0], name='trasnformer')\n",
    "\n",
    "transformer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zvehgftlf3jH"
   },
   "outputs": [],
   "source": [
    "transformer_model.compile(optimizer='rmsprop', loss=custom_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBWadFyrP8Na"
   },
   "source": [
    "上の実装のtargetの3982次元「one-hot」は、padding記号に対しては、全てゼロなので、この無意味なpadding記号にはlossを計算しないようにしたcrossentropy関数である`custom_loss`を使うことにした。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 727554,
     "status": "ok",
     "timestamp": 1620814069326,
     "user": {
      "displayName": "MASATO TAKI",
      "photoUrl": "",
      "userId": "06408555804759539719"
     },
     "user_tz": -540
    },
    "id": "BXShVshIyGPe",
    "outputId": "b1e6d677-2e6a-41ae-a8c6-677d640356b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer_16/decoder_16/decoder_module_34/mhsa_module_70/multi_head_self_attention_104/dense_572/kernel:0', 'transformer_16/decoder_16/decoder_module_34/mhsa_module_70/multi_head_self_attention_104/dense_573/kernel:0', 'transformer_16/decoder_16/decoder_module_34/mhsa_module_70/multi_head_self_attention_104/dense_574/kernel:0', 'transformer_16/decoder_16/decoder_module_34/mhsa_module_70/multi_head_self_attention_104/dense_575/kernel:0', 'transformer_16/decoder_16/decoder_module_34/mhsa_module_70/layer_normalization_174/gamma:0', 'transformer_16/decoder_16/decoder_module_34/mhsa_module_70/layer_normalization_174/beta:0', 'transformer_16/decoder_16/decoder_module_35/mhsa_module_71/multi_head_self_attention_106/dense_582/kernel:0', 'transformer_16/decoder_16/decoder_module_35/mhsa_module_71/multi_head_self_attention_106/dense_583/kernel:0', 'transformer_16/decoder_16/decoder_module_35/mhsa_module_71/multi_head_self_attention_106/dense_584/kernel:0', 'transformer_16/decoder_16/decoder_module_35/mhsa_module_71/multi_head_self_attention_106/dense_585/kernel:0', 'transformer_16/decoder_16/decoder_module_35/mhsa_module_71/layer_normalization_177/gamma:0', 'transformer_16/decoder_16/decoder_module_35/mhsa_module_71/layer_normalization_177/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer_16/decoder_16/decoder_module_34/mhsa_module_70/multi_head_self_attention_104/dense_572/kernel:0', 'transformer_16/decoder_16/decoder_module_34/mhsa_module_70/multi_head_self_attention_104/dense_573/kernel:0', 'transformer_16/decoder_16/decoder_module_34/mhsa_module_70/multi_head_self_attention_104/dense_574/kernel:0', 'transformer_16/decoder_16/decoder_module_34/mhsa_module_70/multi_head_self_attention_104/dense_575/kernel:0', 'transformer_16/decoder_16/decoder_module_34/mhsa_module_70/layer_normalization_174/gamma:0', 'transformer_16/decoder_16/decoder_module_34/mhsa_module_70/layer_normalization_174/beta:0', 'transformer_16/decoder_16/decoder_module_35/mhsa_module_71/multi_head_self_attention_106/dense_582/kernel:0', 'transformer_16/decoder_16/decoder_module_35/mhsa_module_71/multi_head_self_attention_106/dense_583/kernel:0', 'transformer_16/decoder_16/decoder_module_35/mhsa_module_71/multi_head_self_attention_106/dense_584/kernel:0', 'transformer_16/decoder_16/decoder_module_35/mhsa_module_71/multi_head_self_attention_106/dense_585/kernel:0', 'transformer_16/decoder_16/decoder_module_35/mhsa_module_71/layer_normalization_177/gamma:0', 'transformer_16/decoder_16/decoder_module_35/mhsa_module_71/layer_normalization_177/beta:0'] when minimizing the loss.\n",
      "1000/1000 [==============================] - 51s 45ms/step - loss: 1.5999\n",
      "Epoch 2/16\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 1.2691\n",
      "Epoch 3/16\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 1.2016\n",
      "Epoch 4/16\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.1708\n",
      "Epoch 5/16\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 1.1395\n",
      "Epoch 6/16\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 1.0994\n",
      "Epoch 7/16\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 1.0926\n",
      "Epoch 8/16\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 1.0979\n",
      "Epoch 9/16\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 1.1144\n",
      "Epoch 10/16\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 1.1149\n",
      "Epoch 11/16\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 1.1163\n",
      "Epoch 12/16\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 1.1275\n",
      "Epoch 13/16\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.1341\n",
      "Epoch 14/16\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.1365\n",
      "Epoch 15/16\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.1449\n",
      "Epoch 16/16\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 1.1576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c7db6b550>"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_model.fit(x=[encoder_input_data, decoder_input_data, encoder_mask_data, decoder_mask_look_ahead_data], y=decoder_target_data, epochs=16, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CNBVIO5C-Vk"
   },
   "outputs": [],
   "source": [
    "n_heads = 8\n",
    "n_layers = 2\n",
    "d_ff = 512\n",
    "d_model = 128\n",
    "do_rate = 0.2\n",
    "\n",
    "encoder_inputs = layers.Input(shape=(max_seq_len,), name='encoder_input')\n",
    "decoder_inputs = layers.Input(shape=(max_seq_len,), name='decoder_input')\n",
    "\n",
    "encoder_mask = layers.Input(shape=(1,1,max_seq_len))\n",
    "decoder_look_ahead_mask = layers.Input(shape=(1,max_seq_len,max_seq_len))\n",
    "\n",
    "transformer = Transformer(n_layers, num_encoder_tokens, num_decoder_tokens, max_seq_len, d_model, n_heads, do_rate)\n",
    "y = transformer(encoder_inputs, decoder_inputs, mask_enc=encoder_mask, mask_dec=encoder_mask, mask_look_ahead=decoder_look_ahead_mask, training=True)\n",
    "\n",
    "transformer_model = tf.keras.models.Model(inputs=[encoder_inputs, decoder_inputs, encoder_mask, decoder_look_ahead_mask], outputs=y[0], name='trasnformer')\n",
    "\n",
    "transformer_model.compile(optimizer='rmsprop', loss=custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_8XvE4wDJ4H",
    "outputId": "8e1c39fc-16d8-4789-bcbb-fc386356614a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer_17/decoder_17/decoder_module_36/mhsa_module_74/multi_head_self_attention_110/dense_605/kernel:0', 'transformer_17/decoder_17/decoder_module_36/mhsa_module_74/multi_head_self_attention_110/dense_606/kernel:0', 'transformer_17/decoder_17/decoder_module_36/mhsa_module_74/multi_head_self_attention_110/dense_607/kernel:0', 'transformer_17/decoder_17/decoder_module_36/mhsa_module_74/multi_head_self_attention_110/dense_608/kernel:0', 'transformer_17/decoder_17/decoder_module_36/mhsa_module_74/layer_normalization_184/gamma:0', 'transformer_17/decoder_17/decoder_module_36/mhsa_module_74/layer_normalization_184/beta:0', 'transformer_17/decoder_17/decoder_module_37/mhsa_module_75/multi_head_self_attention_112/dense_615/kernel:0', 'transformer_17/decoder_17/decoder_module_37/mhsa_module_75/multi_head_self_attention_112/dense_616/kernel:0', 'transformer_17/decoder_17/decoder_module_37/mhsa_module_75/multi_head_self_attention_112/dense_617/kernel:0', 'transformer_17/decoder_17/decoder_module_37/mhsa_module_75/multi_head_self_attention_112/dense_618/kernel:0', 'transformer_17/decoder_17/decoder_module_37/mhsa_module_75/layer_normalization_187/gamma:0', 'transformer_17/decoder_17/decoder_module_37/mhsa_module_75/layer_normalization_187/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['transformer_17/decoder_17/decoder_module_36/mhsa_module_74/multi_head_self_attention_110/dense_605/kernel:0', 'transformer_17/decoder_17/decoder_module_36/mhsa_module_74/multi_head_self_attention_110/dense_606/kernel:0', 'transformer_17/decoder_17/decoder_module_36/mhsa_module_74/multi_head_self_attention_110/dense_607/kernel:0', 'transformer_17/decoder_17/decoder_module_36/mhsa_module_74/multi_head_self_attention_110/dense_608/kernel:0', 'transformer_17/decoder_17/decoder_module_36/mhsa_module_74/layer_normalization_184/gamma:0', 'transformer_17/decoder_17/decoder_module_36/mhsa_module_74/layer_normalization_184/beta:0', 'transformer_17/decoder_17/decoder_module_37/mhsa_module_75/multi_head_self_attention_112/dense_615/kernel:0', 'transformer_17/decoder_17/decoder_module_37/mhsa_module_75/multi_head_self_attention_112/dense_616/kernel:0', 'transformer_17/decoder_17/decoder_module_37/mhsa_module_75/multi_head_self_attention_112/dense_617/kernel:0', 'transformer_17/decoder_17/decoder_module_37/mhsa_module_75/multi_head_self_attention_112/dense_618/kernel:0', 'transformer_17/decoder_17/decoder_module_37/mhsa_module_75/layer_normalization_187/gamma:0', 'transformer_17/decoder_17/decoder_module_37/mhsa_module_75/layer_normalization_187/beta:0'] when minimizing the loss.\n",
      "1000/1000 [==============================] - 34s 28ms/step - loss: 1.6323\n",
      "Epoch 2/16\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.2496\n",
      "Epoch 3/16\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.1824\n",
      "Epoch 4/16\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.1281\n",
      "Epoch 5/16\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0952\n",
      "Epoch 6/16\n",
      " 363/1000 [=========>....................] - ETA: 18s - loss: 1.0745"
     ]
    }
   ],
   "source": [
    "transformer_model.fit(x=[encoder_input_data, decoder_input_data, encoder_mask_data, decoder_mask_look_ahead_data], \n",
    "                      y=decoder_target_data, epochs=16, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Cs6g_kj16su"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, max_seq_len, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.pos_encoding = positional_encoding(max_seq_len, d_model)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_dtype = inputs.dtype\n",
    "        pos_encoding = self.pos_encoding\n",
    "        pos_encoding = tf.cast(pos_encoding, dtype=input_dtype)\n",
    "        inputs *= tf.math.sqrt(tf.cast(self.d_model, dtype=input_dtype))\n",
    "\n",
    "        return inputs + pos_encoding\n",
    "\n",
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, n_heads, d_model):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert self.d_model % self.n_heads == 0, 'n_headsはd_modelの因数'\n",
    "\n",
    "        self.d = self.d_model // self.n_heads\n",
    "\n",
    "        self.dense_q = layers.Dense(d_model, use_bias=False)\n",
    "        self.dense_k = layers.Dense(d_model, use_bias=False)\n",
    "        self.dense_v = layers.Dense(d_model, use_bias=False)\n",
    "        self.dense_o = layers.Dense(d_model, use_bias=False)\n",
    "\n",
    "    def call(self, x_q, x_k, x_v, mask):\n",
    "        \n",
    "        q = self.dense_q(x_q)\n",
    "        k = self.dense_k(x_k)\n",
    "        v = self.dense_v(x_v)\n",
    "\n",
    "        max_seq_len = tf.shape(k)[1]\n",
    "        \n",
    "        q = self.split_to_heads(q, max_seq_len)\n",
    "        k = self.split_to_heads(k, max_seq_len)\n",
    "        v = self.split_to_heads(v, max_seq_len)\n",
    "\n",
    "        logit = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "        d_k = tf.shape(k)[-1]\n",
    "        k_dtype = k.dtype\n",
    "        scale = 1/tf.math.sqrt(tf.cast(d_k, k_dtype))\n",
    "        logit *= scale\n",
    "\n",
    "        if mask is not None:\n",
    "            logit += mask*k_dtype.min\n",
    "        \n",
    "        attention_weight = tf.nn.softmax(logit, axis=-1)\n",
    "        attention_output = tf.einsum('nhst,nhtd->nshd', attention_weight, v)\n",
    "        attention_output = tf.reshape(attention_output, (-1, max_seq_len, self.n_heads*self.d))\n",
    "        attention_output = self.dense_o(attention_output)\n",
    "\n",
    "        return attention_output, attention_weight\n",
    "\n",
    "    def split_to_heads(self, x, max_seq_len):\n",
    "        x = tf.reshape(x, (-1, max_seq_len, self.n_heads, self.d))\n",
    "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        return x\n",
    "\n",
    "class MHSAModule(layers.Layer):\n",
    "    def __init__(self, source_vocab_size, max_seq_len, d_model, n_heads, do_rate):\n",
    "        super(MHSAModule, self).__init__()\n",
    "        self.mhsa = MultiHeadSelfAttention(n_heads, d_model)\n",
    "        self.dropout = layers.Dropout(do_rate)\n",
    "        self.add = layers.Add()\n",
    "        self.norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, mask, training=False):\n",
    "        x, att = self.mhsa(inputs, inputs, inputs, mask)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.add([x,inputs])\n",
    "        x = self.norm(x)\n",
    "        return x, att\n",
    "\n",
    "class PointWiseFeedForwardModule(layers.Layer):\n",
    "    def __init__(self, d_model, d_ff, do_rate):\n",
    "        super(PointWiseFeedForwardModule, self).__init__()\n",
    "        self.pwff_1 = layers.Dense(d_ff, activation='relu')\n",
    "        self.pwff_2 = layers.Dense(d_model)\n",
    "        self.dropout = layers.Dropout(do_rate)\n",
    "        self.add = layers.Add()\n",
    "        self.norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.pwff_1(inputs)\n",
    "        x = self.pwff_2(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.add([x,inputs])\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "class EncoderModule(layers.Layer):\n",
    "    def __init__(self, source_vocab_size, max_seq_len, d_model, n_heads, do_rate):\n",
    "        super(EncoderModule, self).__init__()\n",
    "        self.mhsa = MHSAModule(source_vocab_size, max_seq_len, d_model, n_heads, do_rate)\n",
    "        self.pwff = PointWiseFeedForwardModule(d_model, d_ff, do_rate)\n",
    "\n",
    "    def call(self, inputs, mask, training=False):\n",
    "        x, att = self.mhsa(inputs, mask, training)\n",
    "        x = self.pwff(x, training)\n",
    "        return x, att\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, n_layers, source_vocab_size, max_seq_len, d_model, n_heads, do_rate):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.source_vocab_size = source_vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.do_rate = do_rate\n",
    "        self.do = layers.Dropout(do_rate)\n",
    "        self.embedding = layers.Embedding(source_vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(max_seq_len, d_model)\n",
    "        self.mhsa_modules = [EncoderModule(source_vocab_size, max_seq_len, d_model, n_heads, do_rate) for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs, mask_enc, training=False):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.do(x, training=training)\n",
    "        attention_weights = []\n",
    "        for module in self.mhsa_modules:\n",
    "            x, att = module(x, mask_enc, training)\n",
    "            attention_weights.append(att)\n",
    "        return x, attention_weights\n",
    "\n",
    "class MHSAModuleDec(layers.Layer):\n",
    "    def __init__(self, source_vocab_size, max_seq_len, d_model, n_heads, do_rate):\n",
    "        super(MHSAModuleDec, self).__init__()\n",
    "        self.mhsa = MultiHeadSelfAttention(n_heads, d_model)\n",
    "        self.dropout = layers.Dropout(do_rate)\n",
    "        self.add = layers.Add()\n",
    "        self.norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, context, mask, training=False):\n",
    "        x, att = self.mhsa(inputs, context, context, mask)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.add([x,inputs])\n",
    "        x = self.norm(x)\n",
    "        return x, att\n",
    "\n",
    "class DecoderModule(layers.Layer):\n",
    "    def __init__(self, source_vocab_size, max_seq_len, d_model, n_heads, do_rate):\n",
    "        super(DecoderModule, self).__init__()\n",
    "        self.mhsa1 = MHSAModule(source_vocab_size, max_seq_len, d_model, n_heads, do_rate)\n",
    "        self.mhsa2 = MHSAModuleDec(source_vocab_size, max_seq_len, d_model, n_heads, do_rate)\n",
    "        self.pwff = PointWiseFeedForwardModule(d_model, d_ff, do_rate)\n",
    "\n",
    "    def call(self, inputs, enc_outputs, mask, mask_look_ahead, training=False):\n",
    "        x, att1 = self.mhsa1(inputs, mask, training)\n",
    "        x, att2 = self.mhsa2(inputs, enc_outputs, mask_look_ahead, training)\n",
    "        x = self.pwff(x, training)\n",
    "        return x, att1, att2\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, n_layers, target_vocab_size, max_seq_len, d_model, n_heads, do_rate):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.do_rate = do_rate\n",
    "        self.do = layers.Dropout(do_rate)\n",
    "        self.embedding = layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(max_seq_len, d_model)\n",
    "        self.mhsa_modules = [DecoderModule(source_vocab_size, max_seq_len, d_model, n_heads, do_rate) for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs, enc_outputs, mask_dec, mask_look_ahead, training=False):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.do(x)\n",
    "        attention_weights = []\n",
    "        for module in self.mhsa_modules:\n",
    "            x, att1, att2 = module(x, enc_outputs, mask_dec, mask_look_ahead, training)\n",
    "            attention_weights += [[att1, att2]]\n",
    "        return x, attention_weights\n",
    "\n",
    "class Transformer(layers.Layer):\n",
    "    def __init__(self, n_layers, source_vocab_size, target_vocab_size, max_seq_len, d_model, n_heads, do_rate):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.do_rate = do_rate\n",
    "        self.encoder = Encoder(n_layers, source_vocab_size, max_seq_len, d_model, n_heads, do_rate)\n",
    "        self.decoder = Decoder(n_layers, target_vocab_size, max_seq_len, d_model, n_heads, do_rate)\n",
    "        #self.classification = layers.Dense(target_vocab_size-1, activation='softmax')\n",
    "        self.classification = layers.Dense(target_vocab_size-1)\n",
    "\n",
    "    def call(self, enc_inputs, dec_inputs, mask_enc, mask_dec, mask_look_ahead, training=False):\n",
    "\n",
    "        enc_outputs, att_enc = self.encoder(enc_inputs, mask_enc=mask_enc, training=training)\n",
    "        dec_outputs, att_dec = self.decoder(dec_inputs, enc_outputs, mask_dec=mask_dec, mask_look_ahead=mask_look_ahead, training=training)\n",
    "        y = self.classification(dec_outputs)\n",
    "        y = tf.keras.activations.softmax(y, axis=-1)\n",
    "\n",
    "        return y, att_enc + att_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_Uh7SJF6QNG"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqsW8ggu_Nhp"
   },
   "source": [
    "# 問題：\n",
    "学習済みの`transformer`層を使って、学習後に予測を行うモデルを作り翻訳させてみましょう。授業のSeq2Seqの予測の実装を理解すればほとんど同じです。ただし予測時のマスクの扱いについては注意しましょう（auto regressiveにやるので、mask_look_aheadは不要なので、ゼロテンソルを渡しましょう）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZ7NajW1_tVe"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNqUMHiaCPjQEnefVZz4Mv7",
   "collapsed_sections": [],
   "name": "Transformer2.ipynb のコピー",
   "provenance": [
    {
     "file_id": "1kKAulaRfQDjF_OhBlECstAcy2Zt8dmAV",
     "timestamp": 1620814307021
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
