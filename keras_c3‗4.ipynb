{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation=\"relu\", input_shape=(784,)))\n",
    "\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = layers.Input(shape=(784, ))\n",
    "\n",
    "x = layers.Dense(32, activation= \"relu\")(input_tensor)\n",
    "\n",
    "output_tensor = layers.Dense(10, activation = \"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs=input_tensor, outputs= output_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr=0.001),\n",
    "             loss=\"mse\",\n",
    "              metrics=[\"accuracy\"]\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(input_tensor, target_tensor, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data , test_labels) = \\\n",
    "    imdb.load_data(num_words = 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([max(sequence) for sequence in train_data ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict(\n",
    "    [(value, key) for (key, value) in word_index.items()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_review = \".\".join(\n",
    "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[0]  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension = 10000) :\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    \n",
    "    for i , sequences in enumerate(sequences):\n",
    "        results[i, sequences] = 1.\n",
    "    \n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]\n",
    "y_train = np.asarray(train_labels).astype(\"float32\")\n",
    "y_test = np.asarray(test_labels).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation=\"relu\", input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "             loss=\"binary_crossentropy\",\n",
    "             metrics=[\"accuracy\"]\n",
    "             )\n",
    "\n",
    "from keras import optimizers\n",
    "model.compile(optimizer = optimizers.RMSprop(lr=0.001),\n",
    "             loss = \"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr=0.001),\n",
    "             loss = losses.binary_crossentropy,\n",
    "              metrisc=[metrics.binary_accuracy]\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000: ]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000: ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "             loss = \"binary_crossentropy\",\n",
    "            metrics =[\"acc\"]\n",
    "             )\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512, validation_data=(x_val, y_val))\n",
    "#                    batch_size=512, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\" Training loss\")\n",
    "\n",
    "plt.plot(epochs, val_loss_values, \"b\", label= \"Validation loss\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(16, activation= \"relu\", input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation= \"relu\"))\n",
    "model.add(layers.Dense(1, activation= \"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "results = model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# キャパシティが小さいモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Sequential()\n",
    "\n",
    "model2.add(layers.Dense(4, activation= \"relu\", input_shape=(10000,)))\n",
    "model2.add(layers.Dense(4, activation= \"relu\"))\n",
    "model2.add(layers.Dense(1, activation= \"sigmoid\"))\n",
    "\n",
    "model2.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model2.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "results2 = model2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "model22 = models.Sequential()\n",
    "model22.add(layers.Dense(4, activation= \"relu\", input_shape=(10000,)))\n",
    "model22.add(layers.Dense(4, activation= \"relu\"))\n",
    "model22.add(layers.Dense(1, activation= \"sigmoid\"))\n",
    "model22.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history22 = model22.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512, validation_data=(x_val, y_val))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict22 = history22.history\n",
    "loss_values22 = history_dict22[\"loss\"]\n",
    "val_loss_values22 = history_dict22[\"val_loss\"]\n",
    "\n",
    "epochs22 = range(1, len(loss_values22) + 1)\n",
    "\n",
    "plt.plot(epochs22, loss_values22, \"bo\", label=\" Training loss\")\n",
    "plt.plot(epochs22, val_loss_values22, \"b\", label= \"Validation loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# キャパシティが大きいモデル\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3 = models.Sequential()\n",
    "\n",
    "# model3.add(layers.Dense(512, activation= \"relu\", input_shape=(10000,)))\n",
    "# model3.add(layers.Dense(512, activation= \"relu\"))\n",
    "# model3.add(layers.Dense(1, activation= \"sigmoid\"))\n",
    "\n",
    "# model3.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# model3.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "# results3 = model3.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "model4 = models.Sequential()\n",
    "model4.add(layers.Dense(512, activation= \"relu\", input_shape=(10000,)))\n",
    "model4.add(layers.Dense(512, activation= \"relu\"))\n",
    "model4.add(layers.Dense(1, activation= \"sigmoid\"))\n",
    "model4.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history4 = model4.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512, validation_data=(x_val, y_val))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict4 = history4.history\n",
    "loss_values4 = history_dict4[\"loss\"]\n",
    "val_loss_values4 = history_dict4[\"val_loss\"]\n",
    "\n",
    "epochs4 = range(1, len(loss_values4) + 1)\n",
    "\n",
    "plt.plot(epochs4, loss_values4, \"bo\", label=\" Training loss\")\n",
    "plt.plot(epochs4, val_loss_values4, \"b\", label= \"Validation loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
