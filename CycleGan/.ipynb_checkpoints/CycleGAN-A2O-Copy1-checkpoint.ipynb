{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#  独自ライブラリー： mshow\n",
    "# (複数に対応したノートブック上画像表示)\n",
    "##################################\n",
    "import cv2;import numpy as np;import matplotlib as mpl;import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def mshow(img1=None, img2=None, img3=None, img4=None, img5=None, *, img_list = []):\n",
    "\n",
    "    imgs = list(filter( lambda x: x is not None, [img1, img2, img3, img4, img5])) \n",
    "    imgs.extend(img_list)\n",
    "    \n",
    "    if len(imgs) == 1:\n",
    "        # 一枚のとき\n",
    "        imgs[0] = imgs[0].astype(np.uint8)\n",
    "        im4p = cv2.cvtColor(imgs[0], cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(im4p)\n",
    "\n",
    "    elif len(imgs) < 10:\n",
    "        # 複数枚のとき。横に並べていく\n",
    "        plt.figure(figsize=(len(imgs)*4, len(imgs)*4))\n",
    "        fig_exh_base = 100+len(imgs)*10\n",
    "        for idx, tmp_img in enumerate(imgs):\n",
    "            tmp_img = tmp_img.astype(np.uint8)\n",
    "            tmp_im4p = cv2.cvtColor(tmp_img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            plt.subplot(fig_exh_base+idx+1)\n",
    "            plt.imshow(tmp_im4p)\n",
    "        \n",
    "    else :\n",
    "        plt.figure(figsize=(4*4, 4*4))\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                \n",
    "                if len(imgs) < 5*i+j+1:\n",
    "                    break\n",
    "                tmp_img = imgs[5*i+j].astype(np.uint8)\n",
    "                tmp_im4p = cv2.cvtColor(tmp_img, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                \n",
    "                plt.subplot2grid((5,5), (i,j))\n",
    "                plt.imshow(tmp_im4p)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.18</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Warning: You are not running the latest version of PixieDust. Current is 1.1.18, Latest is 1.1.19</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div>Please copy and run the following command in a new cell to upgrade: <span style=\"background-color:#ececec;font-family:monospace;padding:0 5px\">!pip install --user --upgrade pixiedust</span></div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Please restart kernel after upgrading.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 標準使用ライブラリー\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# 追記\n",
    "import json\n",
    "import datetime\n",
    "import math\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# debug\n",
    "#%pdb on\n",
    "\n",
    "import pixiedust #%pixie_debugger\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "\n",
    "# tfがエラーはかないため\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像サイズ\n",
    "img_size = 128\n",
    "channels = 3\n",
    "img_shape = (img_size, img_size, channels)\n",
    "\n",
    "# 学習の設定\n",
    "batch_size = 32\n",
    "epochs = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像のデータジェネレータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 995 images belonging to 1 classes.\n",
      "Found 1019 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def preprocessing_function(x):\n",
    "    return x / 127.5 - 1\n",
    "\n",
    "A_datagen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                 height_shift_range=0.1,\n",
    "                 preprocessing_function = preprocessing_function\n",
    "                 )\n",
    "B_datagen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                 height_shift_range=0.1,\n",
    "                 preprocessing_function = preprocessing_function\n",
    "                 )\n",
    "\n",
    "# apple画像へのpathを渡す\n",
    "A_generator = A_datagen.flow_from_directory('./apple2orange/trainA',\n",
    "                                            class_mode=None,\n",
    "                                            batch_size=batch_size,\n",
    "                                            target_size=(img_size, img_size), \n",
    "                                            color_mode='rgb')\n",
    "\n",
    "# orange画像へのpathを渡す\n",
    "B_generator = B_datagen.flow_from_directory('./apple2orange/trainB',\n",
    "                                            class_mode=None, \n",
    "                                            batch_size=batch_size,\n",
    "                                            target_size=(img_size, img_size), \n",
    "                                            color_mode='rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "kernel_init = RandomNormal(mean=0.0, stddev=0.02)\n",
    "gamma_init = RandomNormal(mean=0.0, stddev=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow_addons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, UpSampling2D, BatchNormalization, Conv2D, Activation, Dropout, Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU, LayerNormalization, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "\n",
    "patch_size = int(img_size/2**4)\n",
    "patch_shape = (patch_size, patch_size, 1)\n",
    "\n",
    "\n",
    "def build_generator(filters=32):\n",
    "    \n",
    "    model_input = Input(shape=img_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    x = Conv2D(filters, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(model_input)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x1 = InstanceNormalization(gamma_initializer=gamma_init)(x)\n",
    "    \n",
    "    x = Conv2D(filters*2, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x1)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x2 = InstanceNormalization(gamma_initializer=gamma_init)(x)\n",
    "    \n",
    "    x = Conv2D(filters*4, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x2)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x3 = InstanceNormalization()(x)  \n",
    "    \n",
    "    x = Conv2D(filters*8, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x3)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x4 = InstanceNormalization(gamma_initializer=gamma_init)(x)\n",
    "\n",
    "    \n",
    "    # Decoder\n",
    "    x = UpSampling2D((2, 2))(x4)\n",
    "    x = Conv2D(filters*4, kernel_size=4, strides=1, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = InstanceNormalization(gamma_initializer=gamma_init)(x)  \n",
    "    x = Concatenate()([x, x3])\n",
    "    \n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(filters*2, kernel_size=4, strides=1, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = InstanceNormalization(gamma_initializer=gamma_init)(x)  \n",
    "    x = Concatenate()([x, x2])\n",
    "    \n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(filters, kernel_size=4, strides=1, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = InstanceNormalization(gamma_initializer=gamma_init)(x)  \n",
    "    x = Concatenate()([x, x1])\n",
    "    \n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(3, kernel_size=4, strides=1, padding=\"same\", activation=\"tanh\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "\n",
    "    model = Model(model_input, x)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator(filters=64):\n",
    "    \n",
    "    model_input = Input(shape=img_shape)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(model_input)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters*2, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = InstanceNormalization(gamma_initializer=gamma_init)(x)\n",
    "    \n",
    "    x = Conv2D(filters*4, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = InstanceNormalization(gamma_initializer=gamma_init)(x)  \n",
    "    \n",
    "    x = Conv2D(filters*8, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = InstanceNormalization(gamma_initializer=gamma_init)(x)\n",
    "    \n",
    "    x = Conv2D(1, kernel_size=4, strides=1, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "    \n",
    "    model = Model(model_input, x)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 64, 64)        3072      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 128)       131072    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "instance_normalization (Inst (None, 32, 32, 128)       256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 256)       524288    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_1 (In (None, 16, 16, 256)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         2097152   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_2 (In (None, 8, 8, 512)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 1)           8192      \n",
      "=================================================================\n",
      "Total params: 2,765,568\n",
      "Trainable params: 2,765,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 64)        3072      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 128)       131072    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_3 (In (None, 32, 32, 128)       256       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 256)       524288    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_4 (In (None, 16, 16, 256)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 512)         2097152   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_5 (In (None, 8, 8, 512)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 1)           8192      \n",
      "=================================================================\n",
      "Total params: 2,765,568\n",
      "Trainable params: 2,765,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 32)   1536        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 64, 64, 32)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_6 (Insta (None, 64, 64, 32)   64          leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 64)   32768       instance_normalization_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_7 (Insta (None, 32, 32, 64)   128         leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 128)  131072      instance_normalization_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 16, 16, 128)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_8 (Insta (None, 16, 16, 128)  256         leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 256)    524288      instance_normalization_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 8, 8, 256)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_9 (Insta (None, 8, 8, 256)    512         leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 16, 16, 256)  0           instance_normalization_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 128)  524288      up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 16, 16, 128)  0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_10 (Inst (None, 16, 16, 128)  256         leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 16, 256)  0           instance_normalization_10[0][0]  \n",
      "                                                                 instance_normalization_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 256)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 64)   262144      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 32, 32, 64)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_11 (Inst (None, 32, 32, 64)   128         leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 128)  0           instance_normalization_11[0][0]  \n",
      "                                                                 instance_normalization_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 128)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 32)   65536       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 64, 64, 32)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_12 (Inst (None, 64, 64, 32)   64          leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 64)   0           instance_normalization_12[0][0]  \n",
      "                                                                 instance_normalization_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 64) 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 3)  3072        up_sampling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,546,112\n",
      "Trainable params: 1,546,112\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 32)   1536        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 64, 64, 32)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_13 (Inst (None, 64, 64, 32)   64          leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 64)   32768       instance_normalization_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 32, 32, 64)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_14 (Inst (None, 32, 32, 64)   128         leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 128)  131072      instance_normalization_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 16, 16, 128)  0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_15 (Inst (None, 16, 16, 128)  256         leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 256)    524288      instance_normalization_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 8, 8, 256)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_16 (Inst (None, 8, 8, 256)    512         leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 256)  0           instance_normalization_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 128)  524288      up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 16, 16, 128)  0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_17 (Inst (None, 16, 16, 128)  256         leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 256)  0           instance_normalization_17[0][0]  \n",
      "                                                                 instance_normalization_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 256)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 64)   262144      up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 32, 32, 64)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_18 (Inst (None, 32, 32, 64)   128         leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 128)  0           instance_normalization_18[0][0]  \n",
      "                                                                 instance_normalization_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 128)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 32)   65536       up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 64, 64, 32)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_19 (Inst (None, 64, 64, 32)   64          leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 64)   0           instance_normalization_19[0][0]  \n",
      "                                                                 instance_normalization_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 64) 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 128, 128, 3)  3072        up_sampling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,546,112\n",
      "Trainable params: 1,546,112\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "lambda_cycyle = 10.\n",
    "lambda_id = 5.\n",
    "\n",
    "D_A = build_discriminator()\n",
    "D_B = build_discriminator()\n",
    "\n",
    "D_A.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "D_B.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "G_AB = build_generator()\n",
    "G_BA = build_generator()\n",
    "\n",
    "# 入力画像のためのプレースホルダー\n",
    "real_A = Input(shape=img_shape)\n",
    "real_B = Input(shape=img_shape)\n",
    "\n",
    "# 生成器一回でできるフェイク画像\n",
    "fake_A = G_BA(real_B)\n",
    "fake_B = G_AB(real_A)\n",
    "\n",
    "# サイクル整合性のための再構成\n",
    "cycle_A = G_BA(fake_B)\n",
    "cycle_B = G_AB(fake_A)\n",
    "\n",
    "# 同一性\n",
    "same_A = G_BA(real_A)\n",
    "same_B = G_AB(real_B)\n",
    "\n",
    "# fake画像に対する識別器の出力\n",
    "disc_fake_A = D_A(fake_A)\n",
    "disc_fake_B = D_B(fake_B)\n",
    "\n",
    "D_A.trainable = False\n",
    "D_B.trainable = False\n",
    "\n",
    "cycle_gan = Model(inputs=[real_A, real_B],\n",
    "                 outputs=[disc_fake_A, disc_fake_B,\n",
    "                         cycle_A, cycle_B,\n",
    "                         same_A, same_B])\n",
    "\n",
    "cycle_gan.compile(loss=['mse', 'mse', 'mae', 'mae', 'mae', 'mae'],\n",
    "                 loss_weights=[1, 1, lambda_cycyle, lambda_cycyle, lambda_id, lambda_id],\n",
    "                 optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_A_loss_hoistory = []\n",
    "disc_B_loss_hoistory = []\n",
    "disc_loss_hoistory = []\n",
    "\n",
    "gen_loss_hoistory = []\n",
    "\n",
    "\n",
    "def train(epochs, iterations_per_epochs, batch_size=128):\n",
    "    \n",
    "    valid = np.ones((batch_size,) + patch_shape)\n",
    "    fake = np.zeros((batch_size,) + patch_shape)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(iterations_per_epochs):\n",
    "            \n",
    "            batch_A = next(A_generator)\n",
    "            batch_B = next(B_generator)\n",
    "            \n",
    "            # generatorのミニバッチの余りの処理。もっと実装を賢くし直した方がいい\n",
    "            batch_size_modified = batch_size\n",
    "            if batch_A.shape[0]!=batch_B.shape[0]:\n",
    "                batch_size_modified = min(batch_A.shape[0], batch_B.shape[0])\n",
    "                \n",
    "            batch_A = batch_A[:batch_size_modified]\n",
    "            batch_B = batch_B[:batch_size_modified]\n",
    "            \n",
    "            fake_B = G_AB.predict(batch_A)\n",
    "            fake_A = G_BA.predict(batch_B)\n",
    "            \n",
    "            disc_A_loss_real = D_A.train_on_batch(batch_A, valid[:batch_size_modified])\n",
    "            disc_A_loss_fake = D_A.train_on_batch(fake_A, fake[:batch_size_modified])\n",
    "            \n",
    "            disc_A_loss = 0.5 * np.add(disc_A_loss_real, disc_A_loss_fake)\n",
    "            disc_A_loss_hoistory.append(disc_A_loss)\n",
    "            \n",
    "            disc_B_loss_real = D_B.train_on_batch(batch_B, valid[:batch_size_modified])\n",
    "            disc_B_loss_fake = D_B.train_on_batch(fake_B, fake[:batch_size_modified])\n",
    "            \n",
    "            disc_B_loss = 0.5 * np.add(disc_B_loss_real, disc_B_loss_fake)\n",
    "            disc_B_loss_hoistory.append(disc_B_loss)\n",
    "            \n",
    "            d_loss = 0.5 * np.add(disc_A_loss, disc_B_loss)\n",
    "            disc_loss_hoistory.append(d_loss)\n",
    "            \n",
    "            g_loss = cycle_gan.train_on_batch([batch_A, batch_B],\n",
    "                                              [valid[:batch_size_modified], valid[:batch_size_modified],\n",
    "                                               batch_A, batch_B,\n",
    "                                               batch_A, batch_B])\n",
    "            gen_loss_hoistory.append(g_loss)\n",
    "            \n",
    "            if i==0:\n",
    "                print('d loss, g loss:', d_loss[0],  g_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d loss, g loss: 0.4999889470209382 [19.975780487060547, 0.9849926233291626, 0.9843466281890869, 0.6249449253082275, 0.5749436616897583, 0.6241737008094788, 0.5773375630378723]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5691107689d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0miterations_per_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m995\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations_per_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations_per_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-3f2e4246d028>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, iterations_per_epochs, batch_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m                                               [valid[:batch_size_modified], valid[:batch_size_modified],\n\u001b[1;32m     47\u001b[0m                                                \u001b[0mbatch_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_B\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                                                batch_A, batch_B])\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mgen_loss_hoistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iterations_per_epochs = 995//batch_size\n",
    "\n",
    "train(epochs=epochs, iterations_per_epochs=iterations_per_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習後のモデル（`G_AB, G_BA`）にテスト画像を入れて、うまく変換できているかを確認してみる。画素値が`[-1, 1]`に規格化されていることに注意。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan.save(\"./cycle_gan_model_3000.h5\")\n",
    "G_BA.save(\"./g_ba_model_3000.h5\")\n",
    "G_AB.save(\"./g_ab_model_3000.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./apple2orange/testA/img/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "iii = cv2.imread(\"./apple2orange/testA/img/n07740461_10011.jpg\")\n",
    "\n",
    "jjj1 = cv2.imread(\"./apple2orange/testB/img/n07749192_1011.jpg\")\n",
    "jjj2 = cv2.imread(\"./apple2orange/testB/img/n07749192_1010.jpg\")\n",
    "jjj = cv2.imread(\"./apple2orange/testB/img/n07749192_10081.jpg\")\n",
    "\n",
    "result = G_BA.predict(iii[np.newaxis, :, :, :])\n",
    "\n",
    "# # A_datagen(iii)\n",
    "# [,jjj[np.newaxis, :, :, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mshow((result[0]+1)*127.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iii[np.newaxis, :, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "255/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./apple2orange/testA/img/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls \"./apple2orange/testA/img/n07740461_10011.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mshow(iii )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model\n",
    "results = G_AB.predict(next(A_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(\"img\",np.array(results[0]*127+127).astype(int))\n",
    "# plt.imshow(np.array(results[0]*127+127).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
