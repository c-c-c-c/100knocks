{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像サイズ\n",
    "img_size = 128\n",
    "channels = 3\n",
    "img_shape = (img_size, img_size, channels)\n",
    "\n",
    "# 学習の設定\n",
    "batch_size = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像のデータジェネレータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def preprocessing_function(x):\n",
    "    return x / 127.5 - 1\n",
    "\n",
    "A_datagen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                 height_shift_range=0.1,\n",
    "                 preprocessing_function = preprocessing_function\n",
    "                 )\n",
    "B_datagen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                 height_shift_range=0.1,\n",
    "                 preprocessing_function = preprocessing_function\n",
    "                 )\n",
    "\n",
    "# apple画像へのpathを渡す\n",
    "A_generator = A_datagen.flow_from_directory('./apple2orange/trainA',\n",
    "                                            class_mode=None,\n",
    "                                            batch_size=batch_size,\n",
    "                                            target_size=(img_size, img_size), \n",
    "                                            color_mode='rgb')\n",
    "\n",
    "# orange画像へのpathを渡す\n",
    "B_generator = B_datagen.flow_from_directory('./apple2orange/trainB',\n",
    "                                            class_mode=None, \n",
    "                                            batch_size=batch_size,\n",
    "                                            target_size=(img_size, img_size), \n",
    "                                            color_mode='rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "kernel_init = RandomNormal(mean=0.0, stddev=0.02)\n",
    "gamma_init = RandomNormal(mean=0.0, stddev=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, UpSampling2D, BatchNormalization, Conv2D, Activation, Dropout, Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU, LayerNormalization, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "\n",
    "patch_size = int(img_size/2**4)\n",
    "patch_shape = (patch_size, patch_size, 1)\n",
    "\n",
    "\n",
    "def build_generator(filters=32):\n",
    "    \n",
    "    model_input = Input(shape=img_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    x = Conv2D(filters, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(model_input)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x1 = InstanceNormalization(gamma_initializer=gamma_init)(x)\n",
    "    \n",
    "    x = Conv2D(filters*2, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x1)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x2 = InstanceNormalization(gamma_initializer=gamma_init)(x)\n",
    "    \n",
    "    x = Conv2D(filters*4, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x2)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x3 = InstanceNormalization()(x)  \n",
    "    \n",
    "    x = Conv2D(filters*8, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x3)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x4 = InstanceNormalization(gamma_initializer=gamma_init)(x)\n",
    "\n",
    "    \n",
    "    # Decoder\n",
    "    x = UpSampling2D((2, 2))(x4)\n",
    "    x = Conv2D(filters*4, kernel_size=4, strides=1, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = InstanceNormalization(gamma_initializer=gamma_init)(x)  \n",
    "    x = Concatenate()([x, x3])\n",
    "    \n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(filters*2, kernel_size=4, strides=1, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = InstanceNormalization(gamma_initializer=gamma_init)(x)  \n",
    "    x = Concatenate()([x, x2])\n",
    "    \n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(filters, kernel_size=4, strides=1, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = InstanceNormalization(gamma_initializer=gamma_init)(x)  \n",
    "    x = Concatenate()([x, x1])\n",
    "    \n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(3, kernel_size=4, strides=1, padding=\"same\", activation=\"tanh\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "\n",
    "    model = Model(model_input, x)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator(filters=64):\n",
    "    \n",
    "    model_input = Input(shape=img_shape)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(model_input)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = Conv2D(filters*2, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = InstanceNormalization(gamma_initializer=gamma_init)(x)\n",
    "    \n",
    "    x = Conv2D(filters*4, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = InstanceNormalization(gamma_initializer=gamma_init)(x)  \n",
    "    \n",
    "    x = Conv2D(filters*8, kernel_size=4, strides=2, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = InstanceNormalization(gamma_initializer=gamma_init)(x)\n",
    "    \n",
    "    x = Conv2D(1, kernel_size=4, strides=1, padding=\"same\", use_bias=False, kernel_initializer=kernel_init)(x)\n",
    "    \n",
    "    model = Model(model_input, x)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "lambda_cycyle = 10.\n",
    "lambda_id = 5.\n",
    "\n",
    "D_A = build_discriminator()\n",
    "D_B = build_discriminator()\n",
    "\n",
    "D_A.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "D_B.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "G_AB = build_generator()\n",
    "G_BA = build_generator()\n",
    "\n",
    "# 入力画像のためのプレースホルダー\n",
    "real_A = Input(shape=img_shape)\n",
    "real_B = Input(shape=img_shape)\n",
    "\n",
    "# 生成器一回でできるフェイク画像\n",
    "fake_A = G_BA(real_B)\n",
    "fake_B = G_AB(real_A)\n",
    "\n",
    "# サイクル整合性のための再構成\n",
    "cycle_A = G_BA(fake_B)\n",
    "cycle_B = G_AB(fake_A)\n",
    "\n",
    "# 同一性\n",
    "same_A = G_BA(real_A)\n",
    "same_B = G_AB(real_B)\n",
    "\n",
    "# fake画像に対する識別器の出力\n",
    "disc_fake_A = D_A(fake_A)\n",
    "disc_fake_B = D_B(fake_B)\n",
    "\n",
    "D_A.trainable = False\n",
    "D_B.trainable = False\n",
    "\n",
    "cycle_gan = Model(inputs=[real_A, real_B],\n",
    "                 outputs=[disc_fake_A, disc_fake_B,\n",
    "                         cycle_A, cycle_B,\n",
    "                         same_A, same_B])\n",
    "\n",
    "cycle_gan.compile(loss=['mse', 'mse', 'mae', 'mae', 'mae', 'mae'],\n",
    "                 loss_weights=[1, 1, lambda_cycyle, lambda_cycyle, lambda_id, lambda_id],\n",
    "                 optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_A_loss_hoistory = []\n",
    "disc_B_loss_hoistory = []\n",
    "disc_loss_hoistory = []\n",
    "\n",
    "gen_loss_hoistory = []\n",
    "\n",
    "\n",
    "def train(epochs, iterations_per_epochs, batch_size=128):\n",
    "    \n",
    "    valid = np.ones((batch_size,) + patch_shape)\n",
    "    fake = np.zeros((batch_size,) + patch_shape)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(iterations_per_epochs):\n",
    "            \n",
    "            batch_A = next(A_generator)\n",
    "            batch_B = next(B_generator)\n",
    "            \n",
    "            # generatorのミニバッチの余りの処理。もっと実装を賢くし直した方がいい\n",
    "            batch_size_modified = batch_size\n",
    "            if batch_A.shape[0]!=batch_B.shape[0]:\n",
    "                batch_size_modified = min(batch_A.shape[0], batch_B.shape[0])\n",
    "                \n",
    "            batch_A = batch_A[:batch_size_modified]\n",
    "            batch_B = batch_B[:batch_size_modified]\n",
    "            \n",
    "            fake_B = G_AB.predict(batch_A)\n",
    "            fake_A = G_BA.predict(batch_B)\n",
    "            \n",
    "            disc_A_loss_real = D_A.train_on_batch(batch_A, valid[:batch_size_modified])\n",
    "            disc_A_loss_fake = D_A.train_on_batch(fake_A, fake[:batch_size_modified])\n",
    "            \n",
    "            disc_A_loss = 0.5 * np.add(disc_A_loss_real, disc_A_loss_fake)\n",
    "            disc_A_loss_hoistory.append(disc_A_loss)\n",
    "            \n",
    "            disc_B_loss_real = D_B.train_on_batch(batch_B, valid[:batch_size_modified])\n",
    "            disc_B_loss_fake = D_B.train_on_batch(fake_B, fake[:batch_size_modified])\n",
    "            \n",
    "            disc_B_loss = 0.5 * np.add(disc_B_loss_real, disc_B_loss_fake)\n",
    "            disc_B_loss_hoistory.append(disc_B_loss)\n",
    "            \n",
    "            d_loss = 0.5 * np.add(disc_A_loss, disc_B_loss)\n",
    "            disc_loss_hoistory.append(d_loss)\n",
    "            \n",
    "            g_loss = cycle_gan.train_on_batch([batch_A, batch_B],\n",
    "                                              [valid[:batch_size_modified], valid[:batch_size_modified],\n",
    "                                               batch_A, batch_B,\n",
    "                                               batch_A, batch_B])\n",
    "            gen_loss_hoistory.append(g_loss)\n",
    "            \n",
    "            if i==0:\n",
    "                print('d loss, g loss:', d_loss[0],  g_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_per_epochs = 995//batch_size\n",
    "\n",
    "train(epochs=epochs, iterations_per_epochs=iterations_per_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習後のモデル（`G_AB, G_BA`）にテスト画像を入れて、うまく変換できているかを確認してみる。画素値が`[-1, 1]`に規格化されていることに注意。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
