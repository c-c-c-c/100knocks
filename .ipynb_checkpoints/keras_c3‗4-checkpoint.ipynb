{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation=\"relu\", input_shape=(784,)))\n",
    "\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = layers.Input(shape=(784, ))\n",
    "\n",
    "x = layers.Dense(32, activation= \"relu\")(input_tensor)\n",
    "\n",
    "output_tensor = layers.Dense(10, activation = \"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs=input_tensor, outputs= output_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr=0.001),\n",
    "             loss=\"mse\",\n",
    "              metrics=[\"accuracy\"]\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(input_tensor, target_tensor, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data , test_labels) = \\\n",
    "    imdb.load_data(num_words = 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict(\n",
    "    [(value, key) for (key, value) in word_index.items()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_review = \".\".join(\n",
    "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[0]  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"?.this.film.was.just.brilliant.casting.location.scenery.story.direction.everyone's.really.suited.the.part.they.played.and.you.could.just.imagine.being.there.robert.?.is.an.amazing.actor.and.now.the.same.being.director.?.father.came.from.the.same.scottish.island.as.myself.so.i.loved.the.fact.there.was.a.real.connection.with.this.film.the.witty.remarks.throughout.the.film.were.great.it.was.just.brilliant.so.much.that.i.bought.the.film.as.soon.as.it.was.released.for.?.and.would.recommend.it.to.everyone.to.watch.and.the.fly.fishing.was.amazing.really.cried.at.the.end.it.was.so.sad.and.you.know.what.they.say.if.you.cry.at.a.film.it.must.have.been.good.and.this.definitely.was.also.?.to.the.two.little.boy's.that.played.the.?.of.norman.and.paul.they.were.just.brilliant.children.are.often.left.out.of.the.?.list.i.think.because.the.stars.that.play.them.all.grown.up.are.such.a.big.profile.for.the.whole.film.but.these.children.are.amazing.and.should.be.praised.for.what.they.have.done.don't.you.think.the.whole.story.was.so.lovely.because.it.was.true.and.was.someone's.life.after.all.that.was.shared.with.us.all\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension = 10000) :\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    \n",
    "    for i , sequences in enumerate(sequences):\n",
    "        results[i, sequences] = 1.\n",
    "    \n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]\n",
    "y_train = np.asarray(train_labels).astype(\"float32\")\n",
    "y_test = np.asarray(test_labels).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation=\"relu\", input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "             loss=\"binary_crossentropy\",\n",
    "             metrics=[\"accuracy\"]\n",
    "             )\n",
    "\n",
    "from keras import optimizers\n",
    "model.compile(optimizer = optimizers.RMSprop(lr=0.001),\n",
    "             loss = \"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr=0.001),\n",
    "             loss = losses.binary_crossentropy,\n",
    "              metrisc=[metrics.binary_accuracy]\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000: ]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000: ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 2s 151us/step - loss: 0.5099 - acc: 0.7957 - val_loss: 0.3759 - val_acc: 0.8750\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.3010 - acc: 0.9031 - val_loss: 0.3118 - val_acc: 0.8833\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 2s 105us/step - loss: 0.2213 - acc: 0.9279 - val_loss: 0.3235 - val_acc: 0.8687\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.1762 - acc: 0.9442 - val_loss: 0.2959 - val_acc: 0.8818\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 2s 105us/step - loss: 0.1430 - acc: 0.9540 - val_loss: 0.3161 - val_acc: 0.8763\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 2s 105us/step - loss: 0.1202 - acc: 0.9629 - val_loss: 0.3203 - val_acc: 0.8802\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0998 - acc: 0.9714 - val_loss: 0.3164 - val_acc: 0.8794\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0860 - acc: 0.9755 - val_loss: 0.3252 - val_acc: 0.8813\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 2s 105us/step - loss: 0.0710 - acc: 0.9805 - val_loss: 0.3466 - val_acc: 0.8802\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 2s 105us/step - loss: 0.0569 - acc: 0.9857 - val_loss: 0.4024 - val_acc: 0.8694\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 2s 105us/step - loss: 0.0495 - acc: 0.9886 - val_loss: 0.3945 - val_acc: 0.8779\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0389 - acc: 0.9919 - val_loss: 0.4305 - val_acc: 0.8776\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0337 - acc: 0.9926 - val_loss: 0.4529 - val_acc: 0.8739\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0270 - acc: 0.9953 - val_loss: 0.4843 - val_acc: 0.8713\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0221 - acc: 0.9964 - val_loss: 0.5237 - val_acc: 0.8729\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0171 - acc: 0.9976 - val_loss: 0.5587 - val_acc: 0.8707\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 2s 114us/step - loss: 0.0154 - acc: 0.9975 - val_loss: 0.5866 - val_acc: 0.8692\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 2s 106us/step - loss: 0.0116 - acc: 0.9980 - val_loss: 0.6214 - val_acc: 0.8679\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 2s 115us/step - loss: 0.0073 - acc: 0.9996 - val_loss: 0.6606 - val_acc: 0.8636\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 2s 116us/step - loss: 0.0086 - acc: 0.9985 - val_loss: 0.7004 - val_acc: 0.8636\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "             loss = \"binary_crossentropy\",\n",
    "            metrics =[\"acc\"]\n",
    "             )\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512, validation_data=(x_val, y_val))\n",
    "#                    batch_size=512, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcab408fc50>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\" Training loss\")\n",
    "\n",
    "plt.plot(epochs, val_loss_values, \"b\", label= \"Validation loss\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 0.4610 - accuracy: 0.8310\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 63us/step - loss: 0.2653 - accuracy: 0.9080\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 63us/step - loss: 0.2047 - accuracy: 0.9262\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 64us/step - loss: 0.1703 - accuracy: 0.9402\n",
      "25000/25000 [==============================] - 4s 165us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(16, activation= \"relu\", input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation= \"relu\"))\n",
    "model.add(layers.Dense(1, activation= \"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "results = model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2874737310600281, 0.8866400122642517]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21028802],\n",
       "       [0.9998517 ],\n",
       "       [0.85453117],\n",
       "       ...,\n",
       "       [0.09832752],\n",
       "       [0.09015576],\n",
       "       [0.5674623 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# キャパシティが小さいモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.5888 - accuracy: 0.6927\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 0.4912 - accuracy: 0.8435\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.4442 - accuracy: 0.8883\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.4115 - accuracy: 0.9133\n",
      "25000/25000 [==============================] - 3s 113us/step\n"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "\n",
    "model2.add(layers.Dense(4, activation= \"relu\", input_shape=(10000,)))\n",
    "model2.add(layers.Dense(4, activation= \"relu\"))\n",
    "model2.add(layers.Dense(1, activation= \"sigmoid\"))\n",
    "\n",
    "model2.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model2.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "results2 = model2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.453177588596344, 0.859000027179718]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20406008],\n",
       "       [0.55250746],\n",
       "       [0.48456982],\n",
       "       ...,\n",
       "       [0.16706891],\n",
       "       [0.13078827],\n",
       "       [0.3763341 ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 2s 159us/step - loss: 0.5343 - accuracy: 0.7568 - val_loss: 0.3305 - val_accuracy: 0.8649\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.2481 - accuracy: 0.9015 - val_loss: 0.3833 - val_accuracy: 0.8401\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.1483 - accuracy: 0.9419 - val_loss: 0.2938 - val_accuracy: 0.8895\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0838 - accuracy: 0.9735 - val_loss: 0.3526 - val_accuracy: 0.8874\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.0927 - accuracy: 0.9801 - val_loss: 0.3117 - val_accuracy: 0.8857\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 2s 128us/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.5139 - val_accuracy: 0.8829\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 2s 139us/step - loss: 5.0485e-04 - accuracy: 1.0000 - val_loss: 0.6003 - val_accuracy: 0.8849\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 8.1934e-05 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.8845\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 1.6268e-05 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.8847\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 2s 124us/step - loss: 3.2938e-06 - accuracy: 1.0000 - val_loss: 0.9042 - val_accuracy: 0.8846\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 2s 118us/step - loss: 9.0501e-07 - accuracy: 1.0000 - val_loss: 0.9789 - val_accuracy: 0.8849\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 2s 129us/step - loss: 3.1532e-07 - accuracy: 1.0000 - val_loss: 1.0443 - val_accuracy: 0.8845\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 2s 117us/step - loss: 1.1362e-07 - accuracy: 1.0000 - val_loss: 1.1055 - val_accuracy: 0.8844\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 5.0190e-08 - accuracy: 1.0000 - val_loss: 1.1523 - val_accuracy: 0.8843\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 2.8306e-08 - accuracy: 1.0000 - val_loss: 1.1813 - val_accuracy: 0.8841\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 1.9276e-08 - accuracy: 1.0000 - val_loss: 1.2033 - val_accuracy: 0.8844\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 1.4439e-08 - accuracy: 1.0000 - val_loss: 1.2191 - val_accuracy: 0.8844\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 1.1553e-08 - accuracy: 1.0000 - val_loss: 1.2311 - val_accuracy: 0.8845\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 2s 125us/step - loss: 9.6232e-09 - accuracy: 1.0000 - val_loss: 1.2411 - val_accuracy: 0.8847\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 2s 117us/step - loss: 8.2546e-09 - accuracy: 1.0000 - val_loss: 1.2503 - val_accuracy: 0.8847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcbac749910>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "model22 = models.Sequential()\n",
    "model22.add(layers.Dense(4, activation= \"relu\", input_shape=(10000,)))\n",
    "model22.add(layers.Dense(4, activation= \"relu\"))\n",
    "model22.add(layers.Dense(1, activation= \"sigmoid\"))\n",
    "model22.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history22 = model22.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512, validation_data=(x_val, y_val))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict22 = history22.history\n",
    "loss_values22 = history_dict22[\"loss\"]\n",
    "val_loss_values22 = history_dict22[\"val_loss\"]\n",
    "\n",
    "epochs22 = range(1, len(loss_values22) + 1)\n",
    "\n",
    "plt.plot(epochs22, loss_values22, \"bo\", label=\" Training loss\")\n",
    "plt.plot(epochs22, val_loss_values22, \"b\", label= \"Validation loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# キャパシティが大きいモデル\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[10000,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradients_4/dense_17/MatMul_grad/MatMul_1 (defined at /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3009) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_27411]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4840103219bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mresults3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[10000,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradients_4/dense_17/MatMul_grad/MatMul_1 (defined at /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3009) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_27411]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "model3 = models.Sequential()\n",
    "\n",
    "model3.add(layers.Dense(512, activation= \"relu\", input_shape=(10000,)))\n",
    "model3.add(layers.Dense(512, activation= \"relu\"))\n",
    "model3.add(layers.Dense(1, activation= \"sigmoid\"))\n",
    "\n",
    "model3.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model3.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "results3 = model3.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add] name: dense_20/random_uniform/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a8a451743a94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    893\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             self.bias = self.add_weight(shape=(self.units,),\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         weight = K.variable(initializer(shape, dtype=dtype),\n\u001b[0m\u001b[1;32m    280\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             x = K.random_uniform(shape, -limit, limit,\n\u001b[0;32m--> 227\u001b[0;31m                                  dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[1;32m   4355\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         return tf_keras_backend.random_uniform(\n\u001b[0;32m-> 4357\u001b[0;31m             shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed)\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[1;32m   5624\u001b[0m     \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5625\u001b[0m   return random_ops.random_uniform(\n\u001b[0;32m-> 5626\u001b[0;31m       shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed)\n\u001b[0m\u001b[1;32m   5627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0mrnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_random_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add] name: dense_20/random_uniform/"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "model4 = models.Sequential()\n",
    "model4.add(layers.Dense(512, activation= \"relu\", input_shape=(10000,)))\n",
    "model4.add(layers.Dense(512, activation= \"relu\"))\n",
    "model4.add(layers.Dense(1, activation= \"sigmoid\"))\n",
    "model4.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history4 = model4.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512, validation_data=(x_val, y_val))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict4 = history4.history\n",
    "loss_values4 = history_dict4[\"loss\"]\n",
    "val_loss_values4 = history_dict4[\"val_loss\"]\n",
    "\n",
    "epochs4 = range(1, len(loss_values4) + 1)\n",
    "\n",
    "plt.plot(epochs4, loss_values4, \"bo\", label=\" Training loss\")\n",
    "plt.plot(epochs4, val_loss_values4, \"b\", label= \"Validation loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
