{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_99 (LeakyReLU)   (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_15 (Reshape)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_100 (LeakyReLU)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DT (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_101 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_102 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_103 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#リスト8-29:GANの生成者ネットワーク\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim = 32 #最初に設定する潜在空間ベクトル次元\n",
    "height = 32 #縦32ピクセル\n",
    "width = 32 #横32ピクセル\n",
    "channels = 3 #色3チャネル\n",
    "\n",
    "#入力変数(inputは正規分布のランダムノイズ)\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "#入力を16×16、128チャネルの特徴マップに変換\n",
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.LeakyReLU()(x) #活性化関数は\"LeakyReLU\"を使用\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "\n",
    "#畳み込み層を追加(畳込みカーネルサイズは5)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "#32×32にアップサンプリング(畳込みカーネルサイズは4)\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "#さらに畳み込み層を追加(畳込みカーネルサイズは5)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "#32×32、3(channels)チャネル（CIFAR10の画像の形状）の特徴マップを生成(畳込みカーネルサイズは7)\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x) #最後の活性化関数は\"tanh\"を使用\n",
    "\n",
    "#形状がlatent_dim(32)の入力を、形状がx(32,32,3)の画像にマッピング\n",
    "generator = keras.models.Model(generator_input, x) #\"generator\"に生成者ネットワークを格納\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_104 (LeakyReLU)  (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_105 (LeakyReLU)  (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_106 (LeakyReLU)  (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_107 (LeakyReLU)  (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#リスト8-30:GANの判別者ネットワーク\n",
    "\n",
    "#入力変数(shapeは(縦32,横32,カラーチャネル3))\n",
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "#ドロップアウト層を１つ追加:重要なトリック!\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "#全結合分類層(2値分類)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "#disctriminatorモデルをインスタンス化:形状が(32,32,3)の入力で2値分類(fake/real)を実行\n",
    "discriminator = keras.models.Model(discriminator_input, x) #\"discriminator\"に判別者ネットワークを格納\n",
    "discriminator.summary()\n",
    "\n",
    "#オプティマイザで勾配刈込を使用し（clipvalue）、訓練を安定させるために学習率減衰を使用(decay)\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008,\n",
    "                                                   clipvalue=1.0, #（勾配の）絶対値が1.0を超えた時、勾配がクリップ（切り取り）されます(勾配爆発を防ぐ)\n",
    "                                                   decay=1e-8) #各更新の学習率減衰\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#リスト8-31:敵対者ネットワーク(生成者と判別者をつなぎ合わせる)\n",
    "discriminator.trainable = False #discriminatorを凍結するため、重みの更新不可能に設定(これはganモデルにのみ適用される)\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,)) #gan_inputに生成者ネットワークの入力(正規分布のランダムノイズ)\n",
    "gan_output = discriminator(generator(gan_input)) #gan_outputに判別者ネットワークの出力(2値分類)\n",
    "gan = keras.models.Model(gan_input, gan_output) #\"gan\"に生成者ネットワークのランダムノイズを入力し、判別者ネットワークでの2値分類を出力するモデルを格納\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 5.157218933105469\n",
      "adversarial loss: 16.678531646728516\n",
      "discriminator loss: 0.4681757986545563\n",
      "adversarial loss: 2.166520595550537\n",
      "discriminator loss: 0.6988190412521362\n",
      "adversarial loss: 0.7617117762565613\n",
      "discriminator loss: 0.6914531588554382\n",
      "adversarial loss: 0.7520276308059692\n",
      "discriminator loss: 0.6794735789299011\n",
      "adversarial loss: 0.7712185382843018\n",
      "discriminator loss: 0.7266370058059692\n",
      "adversarial loss: 1.0832661390304565\n",
      "discriminator loss: 0.6944710612297058\n",
      "adversarial loss: 0.7505113482475281\n",
      "discriminator loss: 0.6896225810050964\n",
      "adversarial loss: 0.7528076767921448\n",
      "discriminator loss: 0.7008965611457825\n",
      "adversarial loss: 0.7234559059143066\n",
      "discriminator loss: 0.6903657913208008\n",
      "adversarial loss: 0.7569265365600586\n",
      "discriminator loss: 0.6885782480239868\n",
      "adversarial loss: 0.8134918212890625\n",
      "discriminator loss: 0.7022711634635925\n",
      "adversarial loss: 0.7433258295059204\n",
      "discriminator loss: 0.6967802047729492\n",
      "adversarial loss: 0.7462829351425171\n",
      "discriminator loss: 0.6922401785850525\n",
      "adversarial loss: 0.7310592532157898\n",
      "discriminator loss: 0.6678398847579956\n",
      "adversarial loss: 0.837455153465271\n",
      "discriminator loss: 0.6868075728416443\n",
      "adversarial loss: 0.7539303302764893\n",
      "discriminator loss: 0.78697669506073\n",
      "adversarial loss: 0.7738722562789917\n",
      "discriminator loss: 0.7242822647094727\n",
      "adversarial loss: 0.76742023229599\n",
      "discriminator loss: 0.6938368678092957\n",
      "adversarial loss: 0.747028648853302\n",
      "discriminator loss: 0.6840376257896423\n",
      "adversarial loss: 0.7392240762710571\n",
      "discriminator loss: 0.7268377542495728\n",
      "adversarial loss: 0.7958002090454102\n",
      "discriminator loss: 0.6936479806900024\n",
      "adversarial loss: 0.7542227506637573\n",
      "discriminator loss: 0.6902530789375305\n",
      "adversarial loss: 0.7719857096672058\n",
      "discriminator loss: 0.6728620529174805\n",
      "adversarial loss: 0.8107032775878906\n",
      "discriminator loss: 0.6703912615776062\n",
      "adversarial loss: 0.6613828539848328\n",
      "discriminator loss: 0.7027518153190613\n",
      "adversarial loss: 0.7911518812179565\n",
      "discriminator loss: 0.6861311197280884\n",
      "adversarial loss: 0.7502379417419434\n",
      "discriminator loss: 0.7048815488815308\n",
      "adversarial loss: 0.7423492670059204\n",
      "discriminator loss: 0.6851921081542969\n",
      "adversarial loss: 0.6742526888847351\n",
      "discriminator loss: 0.7021616697311401\n",
      "adversarial loss: 0.6875406503677368\n",
      "discriminator loss: 0.7056352496147156\n",
      "adversarial loss: 0.7472127079963684\n",
      "discriminator loss: 0.6955233812332153\n",
      "adversarial loss: 0.7539064288139343\n",
      "discriminator loss: 0.6913109421730042\n",
      "adversarial loss: 0.7329555749893188\n",
      "discriminator loss: 0.6974444389343262\n",
      "adversarial loss: 0.760738730430603\n",
      "discriminator loss: 0.6925822496414185\n",
      "adversarial loss: 0.698325514793396\n",
      "discriminator loss: 0.6964816451072693\n",
      "adversarial loss: 0.7684292793273926\n",
      "discriminator loss: 0.6957637667655945\n",
      "adversarial loss: 0.9448879957199097\n",
      "discriminator loss: 0.6907919645309448\n",
      "adversarial loss: 0.7082341909408569\n",
      "discriminator loss: 0.6958301663398743\n",
      "adversarial loss: 0.7711915969848633\n",
      "discriminator loss: 0.694454550743103\n",
      "adversarial loss: 0.7447646856307983\n",
      "discriminator loss: 0.6829980611801147\n",
      "adversarial loss: 0.6657224893569946\n",
      "discriminator loss: 0.6927911043167114\n",
      "adversarial loss: 0.7437681555747986\n",
      "discriminator loss: 0.6975814700126648\n",
      "adversarial loss: 0.7545210123062134\n",
      "discriminator loss: 0.7036672830581665\n",
      "adversarial loss: 0.7554516792297363\n",
      "discriminator loss: 0.6898294687271118\n",
      "adversarial loss: 0.7316266894340515\n",
      "discriminator loss: 0.7118440270423889\n",
      "adversarial loss: 0.9311419725418091\n",
      "discriminator loss: 0.6860771179199219\n",
      "adversarial loss: 0.7224963903427124\n",
      "discriminator loss: 0.6908532381057739\n",
      "adversarial loss: 0.7511677742004395\n",
      "discriminator loss: 0.7006786465644836\n",
      "adversarial loss: 0.8238975405693054\n",
      "discriminator loss: 0.6914336681365967\n",
      "adversarial loss: 0.7618168592453003\n",
      "discriminator loss: 0.686555027961731\n",
      "adversarial loss: 0.7401673793792725\n",
      "discriminator loss: 0.6877661943435669\n",
      "adversarial loss: 0.7594301700592041\n",
      "discriminator loss: 0.6902931928634644\n",
      "adversarial loss: 0.7832530736923218\n",
      "discriminator loss: 0.6830548644065857\n",
      "adversarial loss: 0.7248689532279968\n",
      "discriminator loss: 0.7115251421928406\n",
      "adversarial loss: 0.9503814578056335\n",
      "discriminator loss: 0.6984521746635437\n",
      "adversarial loss: 0.7388213872909546\n",
      "discriminator loss: 0.6875905990600586\n",
      "adversarial loss: 0.7739067077636719\n",
      "discriminator loss: 0.7074505090713501\n",
      "adversarial loss: 0.8017688989639282\n",
      "discriminator loss: 0.7361767888069153\n",
      "adversarial loss: 0.7047171592712402\n",
      "discriminator loss: 0.7128137946128845\n",
      "adversarial loss: 0.9192999005317688\n",
      "discriminator loss: 0.6894500851631165\n",
      "adversarial loss: 0.9385078549385071\n",
      "discriminator loss: 0.7164562940597534\n",
      "adversarial loss: 0.660111129283905\n",
      "discriminator loss: 0.6849015951156616\n",
      "adversarial loss: 0.7410171031951904\n",
      "discriminator loss: 0.6889839172363281\n",
      "adversarial loss: 0.7655335664749146\n",
      "discriminator loss: 0.720152735710144\n",
      "adversarial loss: 0.7657483220100403\n",
      "discriminator loss: 0.6736301779747009\n",
      "adversarial loss: 0.7544924020767212\n",
      "discriminator loss: 0.690747857093811\n",
      "adversarial loss: 0.6956483125686646\n",
      "discriminator loss: 0.6972792148590088\n",
      "adversarial loss: 0.63805091381073\n",
      "discriminator loss: 0.6834316849708557\n",
      "adversarial loss: 0.7022234201431274\n",
      "discriminator loss: 0.6799658536911011\n",
      "adversarial loss: 0.7637450098991394\n",
      "discriminator loss: 0.674830436706543\n",
      "adversarial loss: 0.7586842775344849\n",
      "discriminator loss: 0.7103723883628845\n",
      "adversarial loss: 1.3779802322387695\n",
      "discriminator loss: 0.7035691142082214\n",
      "adversarial loss: 0.7176575064659119\n",
      "discriminator loss: 0.7051765322685242\n",
      "adversarial loss: 0.7577164769172668\n",
      "discriminator loss: 0.694793164730072\n",
      "adversarial loss: 0.7599713206291199\n",
      "discriminator loss: 0.7582440376281738\n",
      "adversarial loss: 1.8295400142669678\n",
      "discriminator loss: 0.6910975575447083\n",
      "adversarial loss: 0.822490394115448\n",
      "discriminator loss: 0.7267181277275085\n",
      "adversarial loss: 0.7672067284584045\n",
      "discriminator loss: 0.6475552320480347\n",
      "adversarial loss: 0.6110100150108337\n",
      "discriminator loss: 0.6662204265594482\n",
      "adversarial loss: 0.8634014129638672\n",
      "discriminator loss: 0.6586955785751343\n",
      "adversarial loss: 0.7961119413375854\n",
      "discriminator loss: 0.6785750389099121\n",
      "adversarial loss: 0.6928368806838989\n",
      "discriminator loss: 0.7106245160102844\n",
      "adversarial loss: 0.7501863241195679\n",
      "discriminator loss: 0.7222100496292114\n",
      "adversarial loss: 0.9135946035385132\n",
      "discriminator loss: 0.7430682182312012\n",
      "adversarial loss: 1.3147259950637817\n",
      "discriminator loss: 0.717743992805481\n",
      "adversarial loss: 0.8703513145446777\n",
      "discriminator loss: 0.6761671304702759\n",
      "adversarial loss: 0.5596879720687866\n",
      "discriminator loss: 0.6846822500228882\n",
      "adversarial loss: 0.9084903597831726\n",
      "discriminator loss: 0.6465120911598206\n",
      "adversarial loss: 0.8189162015914917\n",
      "discriminator loss: 0.6951245665550232\n",
      "adversarial loss: 0.7932307720184326\n",
      "discriminator loss: 0.6573191285133362\n",
      "adversarial loss: 0.8145472407341003\n",
      "discriminator loss: 0.803138256072998\n",
      "adversarial loss: 1.3635696172714233\n",
      "discriminator loss: 0.7080034017562866\n",
      "adversarial loss: 0.446855366230011\n",
      "discriminator loss: 0.6515806317329407\n",
      "adversarial loss: 0.7429971098899841\n",
      "discriminator loss: 0.6769993901252747\n",
      "adversarial loss: 0.8573430180549622\n",
      "discriminator loss: 0.6522933840751648\n",
      "adversarial loss: 1.2901027202606201\n",
      "discriminator loss: 0.6310141682624817\n",
      "adversarial loss: 0.9170368909835815\n",
      "discriminator loss: 0.6976770162582397\n",
      "adversarial loss: 0.8580517768859863\n",
      "discriminator loss: 0.6490060091018677\n",
      "adversarial loss: 0.8360086679458618\n",
      "discriminator loss: 0.6570870876312256\n",
      "adversarial loss: 0.8370030522346497\n"
     ]
    }
   ],
   "source": [
    "#リスト8-32:GANの訓練の実装\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.datasets import cifar10 #cifar10を読み込むため追加したコード\n",
    "\n",
    "(x_train, y_train), (_, _) = cifar10.load_data() #cifar10を読み込むため追加したコード\n",
    "\n",
    "#カエルの画像（クラス６）を選択\n",
    "x_train = x_train[y_train.flatten() == 6]\n",
    "\n",
    "#データを正規化\n",
    "x_train = x_train.reshape(\n",
    "    (x_train.shape[0],) +\n",
    "    (height, width, channels)).astype('float32') / 255.\n",
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "\n",
    "#生成された画像の保存先を指定\n",
    "save_dir = '8gan' #cifar10データセットを学内サーバで使用するため追加したコード\n",
    "\n",
    "\n",
    "############################## 学習 #################################\n",
    "start = 0\n",
    "for step in range(iterations): #訓練ループを開始(10000回)\n",
    "    \n",
    "    #dircriminatorモデルの訓練用に潜在空間から点をランダムに抽出➀(正規分布のランダムノイズ, shapeは(20,32))\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    #generatorモデルでランダムノイズ(20,32)を形状(20,32,32,3)の画像にマッピング\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "\n",
    "    #本物の画像と組み合わせる\n",
    "    stop = start + batch_size #一回につきバッチサイズ20ずつ足す\n",
    "    real_images = x_train[start: stop] #一回につきバッチサイズ20ずつ本物の画像を抽出(形状を偽物の(20,32,32,3)に合わせる)\n",
    "    combined_images = np.concatenate([generated_images, real_images]) #本物と偽物の画像を連結する(形状が(40,32,32,3))\n",
    "\n",
    "    #本物の画像と偽物の画像を区別するラベルを立てる。　combined_imagesデータに合わせ、最初の20個の偽物は1ベクトル×20(20,1)、\n",
    "    #残りの20個の本物は0ベクトル×20(20,1)とし、それらを連結して正解ラベル×40(40,1)を作る)\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "    \n",
    "    #ラベルにランダムノイズを追加:重要なトリック！\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "\n",
    "    #\"discriminator\"モデルを訓練(.train_on_batchで単一のバッチを使用して1回だけトレーニングする)\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels) #入力には本物、偽物の画像を連結した画像データ、出力には同様の正解ラベル\n",
    "\n",
    "    #dircriminatorモデルの訓練用に潜在空間から点をランダムに抽出➁(正規分布のランダムノイズ, shapeは(20,32))\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "    #「これらはすべて本物の画像」であることを示すラベルを立てる(本物なので0ベクトル×20(20,1))\n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "\n",
    "    #\"gan\"モデルを通じてgeneratorを訓練(ganモデルではdiscriminatorの重みが凍結される)\n",
    "    #訓練データの入力は偽物画像（ランダムノイズ）だが、出力(目的値)は全て本物の画像(0ベクトル)であるとして\n",
    "    #嘘を付いた形の訓練をすることで、偽物画像が本物画像に近づく変換をするモデルに適合していく\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "\n",
    "    #訓練1回終わったら次の訓練では今回使用したものの20枚後の画像データを使用\n",
    "    start += batch_size\n",
    "    \n",
    "    #訓練に全てのカエル画像データ5000枚を使用し終えたら(x_train[4980:5000])、また最初の20枚の訓練データを使用して訓練(x_train[0:20])\n",
    "    if start > len(x_train) - batch_size:\n",
    "      start = 0\n",
    "    \n",
    "    ##################### 訓練100回おきに保存とプロット ######################\n",
    "    if step % 100 == 0:\n",
    "        gan.save_weights('gan.h5') #モデルの重みを保存\n",
    "\n",
    "        #\"discriminator\"および\"gan\"モデルの訓練誤差(binary_crossentropy)を出力\n",
    "        print('discriminator loss:', d_loss)\n",
    "        print('adversarial loss:', a_loss)\n",
    "\n",
    "        #生成された画像を1つずつ保存(generated_frog0.ping, generated_frog100.ping,..., generated_frog9900.ping)\n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'generated_frog' + str(step) + '.png'))\n",
    "\n",
    "        #比較のために本物の画像を1つずつ保存(real_frog0.ping, real_frog100.ping,..., real_frog9900.ping)\n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
