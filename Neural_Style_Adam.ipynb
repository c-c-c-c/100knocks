{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Style_Adam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-c-c-c/100knocks/blob/master/Neural_Style_Adam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tSKpghYzM4j"
      },
      "source": [
        "# <center>tf.KerasによるNeural Styleの実装（勾配法バージョン）</center>\n",
        "\n",
        "Neural Style Transferの理解に行く前に、まずはニューラルネットの定める画風 <b>neural style</b> 、CNNによるテクスチャ合成についてよく理解してみましょう。\n",
        "Neural Style Transferの解説\n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/models/blob/master/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb#scrollTo=fwzYeOqOUH9_\n",
        "\n",
        "とできるだけ似せて作ります(スタイルだけ計算するので、NSTよりはシンプルです)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld7Fnq8nz1Xe"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg9tbRPG4yp9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewccczyHz8eW"
      },
      "source": [
        "# 1. 学習済みVGG19とその特徴マップ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMzurWpKzMPA"
      },
      "source": [
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "\n",
        "vgg_model = VGG19(weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOnoaTsf0AIC"
      },
      "source": [
        "print(len(vgg_model.layers), 'layers')\n",
        "vgg_model.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "medE3vG60K-2"
      },
      "source": [
        "これら22層のうち、[Gatys et al., ]3.2節に書いてあるように、以下では‘conv1 1’, ‘conv2 1’, ‘conv3 1’, ‘conv4 1’, ‘conv5 1’の5層を用います。ですので、その層のインデックスをリストで用意しておきましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4nN2cmX0Gep"
      },
      "source": [
        "style_layer_indexes = [1, 4, 7, 12, 17]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suTJQLNR1GLo"
      },
      "source": [
        "この5個のVGG19の特徴マップを計算するモデルを、`feature_model`という名前で用意しておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFbpI-9B1DjH"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "inputs = vgg_model.layers[0].input\n",
        "features = []\n",
        "for i in style_layer_indexes:\n",
        "    features.append(vgg_model.layers[i].output)\n",
        "\n",
        "feature_model = Model(inputs=inputs, outputs=features)\n",
        "# このモデルのパラメータ（VGGのパラメータ）は学習しない！\n",
        "feature_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjRXJm921cVy"
      },
      "source": [
        "これで画像を入力することで、‘conv1 1’, ‘conv2 1’, ‘conv3 1’, ‘conv4 1’, ‘conv5 1’の5層に対する特徴マップが出力となるモデルができました。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfxIAfyd1brZ"
      },
      "source": [
        "feature_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk1CZsQtf_12"
      },
      "source": [
        "適当なディレクトリに、スタイル画像を保存しておきましょう。今回はスタイルとして、原論文にも多用されていたゴッホの星月夜を選びました："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzHotcxa1u0z"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = '/content/drive/My Drive/style/Gogh.jpg'\n",
        "img = image.load_img(img_path, target_size=(512, 512))\n",
        "# 画像を表示\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oczmoMZc6cRc"
      },
      "source": [
        "この画像を、VGG19（正確には先ほど作った`feature_model`）に入力できるように前処理を行う。今回はVGGを無視して、[-1,1]にピクセル値を規格化する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSKabzlj9xxE"
      },
      "source": [
        "def preprocess_input(raw_img):\n",
        "    x = raw_img.copy()\n",
        "    x = x / (255/2) -1\n",
        "    x = x.astype('float32')\n",
        "    return x\n",
        "\n",
        "def deprocess_img(processed_img):\n",
        "    x = processed_img.copy()\n",
        "    if len(x.shape) == 4:\n",
        "        x = np.squeeze(x, 0)\n",
        "    assert len(x.shape) == 3, (\"Input to deprocess image must be an image of \"\n",
        "                                 \"dimension [1, height, width, channel] or [height, width, channel]\")\n",
        "    if len(x.shape) != 3:\n",
        "        raise ValueError(\"Invalid input to deprocessing image\")\n",
        "    x = (x+1) * (255/2)\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bno451HD5yId"
      },
      "source": [
        "# imageオブジェクトをnumpy ndarrayへ変換\n",
        "x_gogh = image.img_to_array(img)\n",
        "# x[np.newaxis,:,:,:]と同じ。一枚でも計画「行列」化\n",
        "x_gogh = np.expand_dims(x_gogh, axis=0)\n",
        "# VGG専用の前処理関数を使う。1/255ではない\n",
        "x_gogh = preprocess_input(x_gogh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJSeAI--6uJl"
      },
      "source": [
        "では実際に`feature_model`に入力して、5種類の特徴マップそれぞれの初めのチャネルだけを可視化してみましょう："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25DzOh-G6E3p"
      },
      "source": [
        "features_gogh = feature_model.predict(x_gogh)\n",
        "\n",
        "for f in features_gogh:\n",
        "    plt.imshow(f[0,:,:,0])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIFTwHd4hGfb"
      },
      "source": [
        "以下では、これら各層の特徴マップのチャネル相関（Gram行列）が担う星月夜のスタイル情報を可視化することにしましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtuXlIKh65TG"
      },
      "source": [
        "# 2. Neural Style計算の実装\n",
        "\n",
        "このノートブックではNSTの前に、その元となった発見(Texture Synthesis Using Convolutional Neural Networks)\n",
        "\n",
        "https://papers.nips.cc/paper/5633-texture-synthesis-using-convolutional-neural-networks.pdf\n",
        "\n",
        "を勉強します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxoycxTQs9hM"
      },
      "source": [
        "まず、特徴マップ（ndarrayじゃなくてTFのテンソルオブジェクト）からグラム行列を計算する関数、特徴マップとスタイル画像のグラム行列から二乗誤差を計算する関数、生成画像の滑らかさを測るTV誤差関数、そして全体の誤差を計算する関数を順次実装する："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS5WxiZX6Q7A"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K \n",
        "\n",
        "def gram_matrix(f):\n",
        "    # f: feature map. channel last, shape = (1, h, w, c)\n",
        "    #_, h, w, c = tf.shape(f).numpy()\n",
        "    _, h, w, c = K.int_shape(f)\n",
        "    gram = tf.einsum('nijc,nijd->cd', f+0.1, f+0.1)# グラム行列がスパースになるのを防ぐのに、ベースの値を少し上げる\n",
        "    return gram \n",
        "\n",
        "def get_style_loss(feature, gram_target):\n",
        "  # feature: feature map of generated image. channel last, shape = (1, h, w, c)\n",
        "  # gram_target: gram matrix of a feature map for a given target style image\n",
        "  _, h, w, c = K.int_shape(feature)\n",
        "  gram = gram_matrix(feature)\n",
        "  return tf.reduce_sum(tf.square(gram - gram_target))/ (tf.cast(4. * (h**2) *(w**2), tf.float32))\n",
        "\n",
        "def total_variation_loss(x):\n",
        "    # x: image. channel last, shape = (1, H, W, 3)\n",
        "    a = K.square(x[:,  :-1, :, :] - x[:, 1:, :, :])\n",
        "    b = K.square(x[:,  :, :-1, :] - x[:, :, 1:, :])\n",
        "    return tf.reduce_mean(a) + tf.reduce_mean(b)\n",
        "\n",
        "def compute_loss(model, image, style_features, n_layer, lambda_tv, lambda_loss):\n",
        "    # image: generated image\n",
        "    # style_features: list of style feature maps of intermediate layers\n",
        "    # n_layer: the index of the layer of your interesrt\n",
        "    img_features = model(image)  \n",
        "    img_feature = img_features[n_layer]\n",
        "\n",
        "    style_feature = style_features[n_layer]\n",
        "    gram_target = gram_matrix(style_feature)\n",
        "\n",
        "    style_loss =  get_style_loss(img_feature, gram_target)\n",
        "    tv_loss = total_variation_loss(image)\n",
        "  \n",
        "    return  style_loss * lambda_loss  + tv_loss * lambda_tv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-53T4gsqyf1"
      },
      "source": [
        "とりあえず学習途中で止めてもいいように、次のリストに計算結果を貯めていきましょう（このやり方良くないので、ちゃんとスマートに変えてください）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFOtyqN2qznm"
      },
      "source": [
        "imgs = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14v23aWCq1eB"
      },
      "source": [
        "では、実際に最適化でニューラルスタイルを計算する関数を実装します："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tQWYsn3EIT7"
      },
      "source": [
        "def run_neural_styler(style_path, model, n_iterations=1000, n_layer=0, lr_scale_change=1, lambda_tv=1, lambda_loss=1):\n",
        "    # 生成画像のサイズ\n",
        "    size = 512\n",
        "    # style img array (preprocessed)\n",
        "    style_img = image.load_img(style_path, target_size=(size, size))\n",
        "    x_style = image.img_to_array(style_img)\n",
        "    x_style = np.expand_dims(x_style, axis=0)\n",
        "    x_style = preprocess_input(x_style)\n",
        "\n",
        "    _, h_style, w_style, _ = tf.shape(x_style).numpy()\n",
        "    # layerwise features of style image\n",
        "    style_features = feature_model.predict(x_style)\n",
        "\n",
        "    generated_image = np.random.rand(h_style*w_style*3) * 255\n",
        "    generated_image = generated_image.reshape((1, h_style, w_style, 3))\n",
        "\n",
        "    x_gen = preprocess_input(generated_image)\n",
        "    x_gen = tf.Variable(x_gen, dtype=tf.float32)\n",
        "\n",
        "    config = {\n",
        "        'model': model,\n",
        "        'image': x_gen,\n",
        "        'style_features': style_features,\n",
        "        'n_layer': n_layer,\n",
        "        'lambda_tv': lambda_tv,\n",
        "        'lambda_loss': lambda_loss\n",
        "        }\n",
        "    \n",
        "    opt = tf.optimizers.Adam(learning_rate=10, beta_1=0.99, epsilon=1e-1)\n",
        "    #opt = tf.optimizers.SGD(learning_rate=0.1)\n",
        "\n",
        "    for i in range(n_iterations):\n",
        "        with tf.GradientTape() as tape: \n",
        "            loss = compute_loss(**config)\n",
        "        grads = tape.gradient(loss, config['image'])\n",
        "         \n",
        "        opt.apply_gradients([(grads, x_gen)])\n",
        "        clipped = tf.clip_by_value(x_gen, -1, 1)\n",
        "        x_gen.assign(clipped)\n",
        "        \n",
        "        if i%10==0:\n",
        "            loss_value = loss.numpy()\n",
        "            print(i, loss_value)\n",
        "            plot_img = x_gen.numpy()\n",
        "            plot_img = deprocess_img(plot_img)\n",
        "            plt.imshow(plot_img)\n",
        "            plt.show()\n",
        "            # ここの実装適当。スクリプト化するときにきちんとする。\n",
        "            imgs.append(plot_img)\n",
        "\n",
        "    plot_img = x_gen.numpy()\n",
        "    plot_img = deprocess_img(plot_img)\n",
        "\n",
        "    return plot_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkRwg5vVWznB"
      },
      "source": [
        "# 3. `conv1_1`の特徴マップが運ぶスタイルの可視化\n",
        "\n",
        "今回選んだVGG19の5つの層のうち、一番上流にある特徴マップのGram行列が担うneural styleを計算してみましょう。つまり、`n_layer=0`に対するneural styleを可視化します："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gpilTUuQ2ee"
      },
      "source": [
        "neural_style = run_neural_styler('/content/drive/My Drive/style/Gogh.jpg', feature_model, n_iterations=1000, n_layer=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isg2wZEUQPCY"
      },
      "source": [
        "plt.figure(dpi=200)\n",
        "plt.imshow(imgs[-1])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw2kuaRbX3SR"
      },
      "source": [
        "Goghの《星月夜》の`conv1_1` neural styleは、この絵画の画風の高周波成分に対応していることが見て取れました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ-Kfk1bXPrL"
      },
      "source": [
        "# 4. `conv2_1`の特徴マップが運ぶスタイルの可視化\n",
        "\n",
        "上流から数えて2番目にある特徴マップのGram行列が担うneural styleを計算してみましょう。つまり、`n_layer=1`に対するneural styleを可視化します："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EslQ7g1JLkHy"
      },
      "source": [
        "neural_style = run_neural_styler('/content/drive/My Drive/style/Gogh.jpg', feature_model, n_iterations=1000, n_layer=1, lambda_tv= 1, lambda_loss=1/1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nMdQFIVLu9e"
      },
      "source": [
        "plt.figure(dpi=200)\n",
        "plt.imshow(imgs[-1])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpBTBLO2lPcZ"
      },
      "source": [
        "`conv2_1` neural styleはだいぶ大きな画風構造を捉えるようになってきて、画風の周波数は少し低周波側に寄ってきました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqYqXyfRhe-S"
      },
      "source": [
        "# 5. `conv3_1`の特徴マップが運ぶスタイルの可視化\n",
        "\n",
        "上流から数えて3番目にある特徴マップのGram行列が担うneural styleを計算してみましょう。つまり、`n_layer=2`に対するneural styleを可視化します："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoopAtDAfZNo"
      },
      "source": [
        "neural_style  =run_neural_styler('/content/drive/My Drive/style/Gogh.jpg', feature_model, n_iterations=1000, n_layer=2,lambda_tv= 1, lambda_loss=1/10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xQIbbj7fb9k"
      },
      "source": [
        "plt.figure(dpi=200)\n",
        "plt.imshow(imgs[-1])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncj8swl0hgeo"
      },
      "source": [
        "`conv3_1` neural styleはタッチに近いような大きなスケールの画風に近いものになってきました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NQR3XQihhGD"
      },
      "source": [
        "# 6. `conv4_1`の特徴マップが運ぶスタイルの可視化\n",
        "\n",
        "上流から数えて4番目にある特徴マップのGram行列が担うneural styleを計算してみましょう。つまり、`n_layer=3`に対するneural styleを可視化します："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFJFj7GyfeiI"
      },
      "source": [
        "neural_style  =run_neural_styler('/content/drive/My Drive/style/Gogh.jpg', feature_model, n_iterations=1000, n_layer=3, lambda_tv= 2, lambda_loss=1/100000000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcvJwRa5fftT"
      },
      "source": [
        "plt.figure(dpi=200)\n",
        "plt.imshow(imgs[-1])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIIzXCq6oiYv"
      },
      "source": [
        "neural_style = run_neural_styler('/content/drive/My Drive/style/Gogh.jpg', feature_model, n_iterations=1000, n_layer=3, lr_scale_change=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zO3DYHor8Nr"
      },
      "source": [
        "plt.figure(dpi=150)\n",
        "plt.imshow(imgs[-1])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSmFci9Phh80"
      },
      "source": [
        "`conv4_1` neural styleはタッチに近いような大きなスケールの画風に近いものになってきました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IKhelrehidW"
      },
      "source": [
        "# 7. `conv5_1`の特徴マップが運ぶスタイルの可視化\n",
        "\n",
        "上流から数えて5番目にある特徴マップのGram行列が担うneural styleを計算してみましょう。つまり、`n_layer=4`に対するneural styleを可視化します："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwl6bMyulZIq"
      },
      "source": [
        "def compute_loss(model, image, style_features, n_layer, lambda_tv, lambda_loss):\n",
        "    \n",
        "    img_features = model(image)  \n",
        "    img_style = img_features[n_layer]\n",
        "\n",
        "    style_features = style_features[n_layer]\n",
        "    gram_target = gram_matrix(style_features)\n",
        "\n",
        "    style_loss =  get_style_loss(img_style, gram_target)\n",
        "    tv_loss = total_variation_loss(image)\n",
        "  \n",
        "    return  (style_loss  + tv_loss * lambda_tv ) * lambda_loss\n",
        "\n",
        "imgs = []\n",
        "\n",
        "def run_neural_styler(style_path, model, n_iterations=1000, n_layer=0, lr_scale_change=1, lambda_tv=1, lambda_loss=1):\n",
        "    # 生成画像のサイズ\n",
        "    size = 256\n",
        "    # style img array (preprocessed)\n",
        "    style_img = image.load_img(style_path, target_size=(size, size))\n",
        "    x_style = image.img_to_array(style_img)\n",
        "    x_style = np.expand_dims(x_style, axis=0)\n",
        "    x_style = preprocess_input(x_style)\n",
        "\n",
        "    _, h_style, w_style, _ = tf.shape(x_style).numpy()\n",
        "    # layerwise features of style image\n",
        "    style_features = feature_model.predict(x_style)\n",
        "\n",
        "    generated_image = np.random.rand(h_style*w_style*3) * 255\n",
        "    generated_image = generated_image.reshape((1, h_style, w_style, 3))\n",
        "\n",
        "\n",
        "    #generated_image = np.random.normal(1, 0.1, (1, h_style, w_style, 3)) * 255/2\n",
        "    #generated_image = np.clip(generated_image, 0, 255)\n",
        "\n",
        "    x_gen = preprocess_input(generated_image)\n",
        "    x_gen = tf.Variable(x_gen, dtype=tf.float32)\n",
        "\n",
        "    norm_means = np.array([103.939, 116.779, 123.68])\n",
        "    min_vals = -norm_means\n",
        "    max_vals = 255 - norm_means  \n",
        "\n",
        "    config = {\n",
        "        'model': model,\n",
        "        'image': x_gen,\n",
        "        'style_features': style_features,\n",
        "        'n_layer': n_layer,\n",
        "        'lambda_tv': lambda_tv,\n",
        "        'lambda_loss': lambda_loss\n",
        "        }\n",
        "    \n",
        "    #imgs = []\n",
        "    opt = tf.optimizers.Adam(learning_rate=10, beta_1=0.99, epsilon=1e-1)\n",
        "    #opt = tf.optimizers.SGD(learning_rate=0.1)\n",
        "\n",
        "\n",
        "    for i in range(n_iterations):\n",
        "        with tf.GradientTape() as tape: \n",
        "            loss = compute_loss(**config)\n",
        "        grads = tape.gradient(loss, config['image'])\n",
        "         \n",
        "        opt.apply_gradients([(grads, x_gen)])\n",
        "        clipped = tf.clip_by_value(x_gen, -1, 1)\n",
        "        x_gen.assign(clipped)\n",
        "        if i%10==0:\n",
        "            loss_value = loss.numpy()\n",
        "            print(i, loss_value)\n",
        "            plot_img = x_gen.numpy()\n",
        "            plot_img = deprocess_img(plot_img)\n",
        "            plt.imshow(plot_img)\n",
        "            plt.show()\n",
        "            # ここの実装適当。スクリプト化するときにきちんとする。\n",
        "            imgs.append(plot_img)\n",
        "\n",
        "    plot_img = x_gen.numpy()\n",
        "    plot_img = deprocess_img(plot_img)\n",
        "\n",
        "    return plot_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx2SwATEfgT8"
      },
      "source": [
        "neural_style = run_neural_styler('/content/drive/My Drive/style/Gogh.jpg', feature_model, n_iterations=1000, n_layer=4, lambda_tv=1, lambda_loss=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scUJMsXlfhYc"
      },
      "source": [
        "plt.figure(dpi=200)\n",
        "plt.imshow(imgs[-1])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pvSGcQ1hjAv"
      },
      "source": [
        "`conv5_1` neural styleはタッチに近いような大きなスケールの画風に近いものになってきました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU3CjwQWiZPd"
      },
      "source": [
        "## このコードで学んだDLコーディング関係こと\n",
        "\n",
        "- <font color=darkorange>TensorFlow2</font>において自動微分を計算するための勾配テープの使い方（tf.GradientTape API）。\n",
        "\n",
        "- その勾配で直接的に勾配降下をさせる方法（`optimizer.apply_apply_gradients([(grads, variables)])`）\n",
        "\n",
        "詳しくは\n",
        "\n",
        "https://amazon.co.jp/dp/4873119286/\n",
        "\n",
        "の12.3.8と12.3.9。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZttOG4r7lp1B"
      },
      "source": [
        "# 問題\n",
        "スタイル画像の縦横比を正方形に調整する必要はありません。[Gatys et al., Image Style Transfer Using Convolutional Neural Networks]のFigure.1の図の結果のように、星月夜画像の縦横比を維持するように実装を修正して見ましょう。\n",
        "\n",
        "# 問題\n",
        "[Gatys et al., Image Style Transfer Using Convolutional Neural Networks]Figure.1に合わせて、VGG19の‘conv1 2’, ‘conv2 2’, ‘conv3 2’, ‘conv4 2’, ‘conv5 2’でやって見ましょう。\n",
        "\n",
        "# 問題\n",
        "学習率スケジューリングを実装することで、この最適化計算がもう少し改善できるでしょうか？\n",
        "\n",
        "# 問題\n",
        "全く同じものをPytorchで実装して見ましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fROIXcDWjmlW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}