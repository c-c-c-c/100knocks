{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepDream.ipynb のコピー",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-c-c-c/100knocks/blob/master/DeepDream_ipynb_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "598x20LY4CaD"
      },
      "source": [
        "# !pip unistall keras\n",
        "# !pip install keras==2.0.3\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZakOV18_Venw",
        "outputId": "3adfc6f8-071e-43e0-adf4-e0cf0a9710db"
      },
      "source": [
        "from tensorflow.keras.applications import inception_v3\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# ここでは訓練しないため、訓練関連の演算は全て無効にする\n",
        "K.set_learning_phase(0)\n",
        "\n",
        "# InceptionV3ネットワークを畳み込みベースなしで構築\n",
        "# このモデルは学習ずみのImageNetの重み付きで読み込まれる\n",
        "model = inception_v3.InceptionV3(weights='imagenet', include_top=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7EB_bqHV7X_"
      },
      "source": [
        "# 層の名前を係数にマッピング\n",
        "# 係数は最大化の対象となる損失値に、その層の活性化がどれくらい貢献するか\n",
        "# 層の名前はInceptionV3にハードコードされている（model.summary()で確認できる）\n",
        "\n",
        "layer_contributions = {\n",
        "    'mixed2': 0.2,\n",
        "    'mixed3': 3.,\n",
        "    'mixed4': 2.,\n",
        "    'mixed5': 1.5,\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RYAVJeNDgfd"
      },
      "source": [
        "# model.summary()\n",
        "# from keras.utils import plot_model\n",
        "# plot_model(model, to_file='model.png')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI7TZpHoWN0M"
      },
      "source": [
        "# 層の名前を層のインスタンスにマッピング\n",
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "\n",
        "# 損失値を定義\n",
        "loss = K.variable(0.)\n",
        "for layer_name in layer_contributions:\n",
        "  coeff = layer_contributions[layer_name]\n",
        "# 層の出力を取得\n",
        "  activation = layer_dict[layer_name].output\n",
        "  scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
        "# 層の特徴量のL2ノルムをLossに加算\n",
        "  loss = loss + coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / scaling"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyrA9vhD4nwe"
      },
      "source": [
        "# # Get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "# layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "\n",
        "# # Define the loss.\n",
        "# loss = K.variable(0.)\n",
        "# for layer_name in layer_contributions:\n",
        "#     # Add the L2 norm of the features of a layer to the loss.\n",
        "#     coeff = layer_contributions[layer_name]\n",
        "#     activation = layer_dict[layer_name].output\n",
        "\n",
        "#     # We avoid border artifacts by only involving non-border pixels in the loss.\n",
        "#     scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
        "#     loss += coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / scaling"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okH2GcgU5qPA"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAdxUgG_48hn"
      },
      "source": [
        "\n",
        "# This holds our generated image\n",
        "dream = model.input\n",
        "\n",
        "# Compute the gradients of the dream with regard to the loss.\n",
        "grads = K.gradients(loss, dream)[0]\n",
        "\n",
        "# Normalize gradients.\n",
        "grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)\n",
        "\n",
        "# Set up function to retrieve the value\n",
        "# of the loss and gradients given an input image.\n",
        "outputs = [loss, grads]\n",
        "fetch_loss_and_grads = K.function([dream], outputs)\n",
        "\n",
        "def eval_loss_and_grads(x):\n",
        "    outs = fetch_loss_and_grads([x])\n",
        "    loss_value = outs[0]\n",
        "    grad_values = outs[1]\n",
        "    return loss_value, grad_values\n",
        "\n",
        "def gradient_ascent(x, iterations, step, max_loss=None):\n",
        "    for i in range(iterations):\n",
        "        loss_value, grad_values = eval_loss_and_grads(x)\n",
        "        if max_loss is not None and loss_value > max_loss:\n",
        "            break\n",
        "        print('...Loss value at', i, ':', loss_value)\n",
        "        x += step * grad_values\n",
        "    return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRjU_55fW8DN"
      },
      "source": [
        "# # 生成されたドリーム画像を保持するテンソル\n",
        "# dream = model.input\n",
        "# # ドリームの損失関数の勾配を計算\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import GradientTape\n",
        "# # grads = K.gradients(loss, dream)[0]\n",
        "# '''\n",
        "# RuntimeError: tf.gradients is not supported \n",
        "# when eager execution is enabled. Use tf.GradientTape instead.\n",
        "# -> GradientTapeにしてもX\n",
        "# '''\n",
        "\n",
        "# # from tensorflow import GradientTape\n",
        "# grads = GradientTape(loss, dream)\n",
        "# '''\n",
        "# ValueError: Attempt to convert a value (<tensorflow.python.eager.backprop.GradientTape \n",
        "# object at 0x7fae74a2bf98>) with an unsupported type (<class 'tensorflow.python.eager.\n",
        "# backprop.GradientTape'>) to a Tensor.\n",
        "# '''\n",
        "\n",
        "# # import tensorflow as tf\n",
        "# # grads = tf.Graph()\n",
        "# # with grads.as_default():\n",
        "# #     grads = tf.gradients(loss, dream)[0]\n",
        "\n",
        "# '''\n",
        "# TypeError: Cannot convert a symbolic Keras input/output to a numpy array. \n",
        "# This error may indicate that you're trying to pass a symbolic value to a NumPy call, \n",
        "# which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs \n",
        "# to a TF API that does not register dispatching, preventing Keras from automatically \n",
        "# converting the API call to a lambda layer in the Functional Model.\n",
        "# '''\n",
        "\n",
        "# # 勾配を正規化（重要）\n",
        "# grads = grads / K.maximum(K.mean(K.abs(grads)), 1e-7)\n",
        "# # 入力画像に基づいて損失と勾配の値を取得するKeras関数を設定\n",
        "# outputs = [loss, grads]\n",
        "# fetch_loss_and_grads = K.function([dream], outputs)\n",
        "\n",
        "# def eval_loss_andgrads(x):\n",
        "#   outs = fetch_loss_and_grads([x])\n",
        "#   loss_value = outs[0]\n",
        "#   grad_values = outs[1]\n",
        "#   return loss_value, grad_values\n",
        "\n",
        "# def gradient_ascent(x, iterations, step, max_loss=None):\n",
        "#   for i in range(iterations):\n",
        "#     loss_value, grad_values = eval+loss_and_grads(x)\n",
        "#     if max_loss is not None and loss_value >max_loss:\n",
        "#       break\n",
        "#     print('...loss value at', i, ':', loss_value)\n",
        "#     x+= step * grad_values\n",
        "#   return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7rbfRiM3kiJ",
        "outputId": "888f69d8-a7da-4287-afd3-3c52c20658ec"
      },
      "source": [
        "# !pip uninstall -y scipy\n",
        "# !pip install scipy==0.15.1\n",
        "\n",
        "# import scipy\n",
        "\n",
        "!apt install freeimage"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package freeimage\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXFG4cijrzXK",
        "outputId": "27719694-5552-4f60-92f0-27f5921c30f8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "step = 0.01\n",
        "num_octave = 3\n",
        "octave_scale = 1.4\n",
        "iterations = 20\n",
        "\n",
        "max_loss = 10.\n",
        "\n",
        "base_image_path = '/content/hand.jpg'\n",
        "\n",
        "img = preprocess_image(base_image_path)\n",
        "\n",
        "original_shape = img.shape[1:3]\n",
        "successive_shapes = [original_shape]\n",
        "# for i in range(1, num_octave):\n",
        "#   shape = tuple([int_dim / (octave_scale **i)) for dim in original_shape])\n",
        "#   successive_shapes.append(shpae)\n",
        "  \n",
        "for i in range(1, num_octave):\n",
        "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
        "    successive_shapes.append(shape)\n",
        "\n",
        "successive_shapes = successive_shapes[::-1]\n",
        "\n",
        "original_img = np.copy(img)\n",
        "shrunk_original_img = resize_img(img, successive_shapes[0])\n",
        "\n",
        "for shape in successive_shapes:\n",
        "  print('Processing image shape', shape)\n",
        "  img = resize_img(img, shape)\n",
        "  img = gradient_ascent(img,\n",
        "                        iterations=iterations,\n",
        "                          step=step,\n",
        "                          max_loss=max_loss)\n",
        "\n",
        "  \n",
        "  upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
        "  same_size_original = resize_img(original_img, shape)\n",
        "  lost_detail = same_size_original - upscaled_shrunk_original_img\n",
        "  img += lost_detail\n",
        "  shrunk_original_img = resize_img(original_img, shape)\n",
        "  save_img(img, fname='dream_at_scale_' + str(shape) + '.png')\n",
        "\n",
        "save_img(img, fname='final_dream.png')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing image shape (452, 612)\n",
            "...Loss value at 0 : 1.4046388\n",
            "...Loss value at 1 : 1.8369086\n",
            "...Loss value at 2 : 2.5691853\n",
            "...Loss value at 3 : 3.2257445\n",
            "...Loss value at 4 : 3.9715176\n",
            "...Loss value at 5 : 4.7218\n",
            "...Loss value at 6 : 5.4354887\n",
            "...Loss value at 7 : 6.165918\n",
            "...Loss value at 8 : 6.8730354\n",
            "...Loss value at 9 : 7.593799\n",
            "...Loss value at 10 : 8.271179\n",
            "...Loss value at 11 : 8.960426\n",
            "...Loss value at 12 : 9.614954\n",
            "Processing image shape (632, 857)\n",
            "...Loss value at 0 : 3.395297\n",
            "...Loss value at 1 : 4.7819963\n",
            "...Loss value at 2 : 5.8856006\n",
            "...Loss value at 3 : 6.8916492\n",
            "...Loss value at 4 : 7.8377037\n",
            "...Loss value at 5 : 8.712428\n",
            "...Loss value at 6 : 9.546206\n",
            "Processing image shape (886, 1200)\n",
            "...Loss value at 0 : 3.3258421\n",
            "...Loss value at 1 : 4.566557\n",
            "...Loss value at 2 : 5.5755672\n",
            "...Loss value at 3 : 6.5189867\n",
            "...Loss value at 4 : 7.419509\n",
            "...Loss value at 5 : 8.268315\n",
            "...Loss value at 6 : 9.078313\n",
            "...Loss value at 7 : 9.8482065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4dcrnKQ5s5b"
      },
      "source": [
        "import scipy\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def resize_img(img, size):\n",
        "  img=np.copy(img)\n",
        "  factors = (1, float(size[0]) / img.shape[1], float(size[1]) / img.shape[2] ,1)\n",
        "  return scipy.ndimage.zoom(img, factors, order=1)\n",
        "\n",
        "def save_img(img, fname):\n",
        "  pil_img = deprocess_image(np.copy(img))\n",
        "\n",
        "  import imageio\n",
        "  imageio.imwrite('fname.jpg', pil_img)\n",
        "#   scipy.misc.imsave(fname, pil_img)\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "  img = image.load_img(image_path)\n",
        "  img = image.img_to_array(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = inception_v3.preprocess_input(img)\n",
        "  return img\n",
        "\n",
        "def deprocess_image(x):\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "    x = x.reshape((3, x.shape[2], x.shape[3]))\n",
        "    x = x.transpose((1, 2, 0))\n",
        "  else:\n",
        "    # \n",
        "    x = x.reshape((x.shape[1], x.shape[2], 3))\n",
        "  x /= 2.\n",
        "  x += 0.5\n",
        "  x *= 255.\n",
        "  x = np.clip(x, 0, 255).astype('uint8')\n",
        "  return x"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHgGT5G36kOc",
        "outputId": "fea5bff1-1be1-4cdd-b3ba-54eb890ce80b"
      },
      "source": [
        "!apt install imageio "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package imageio\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}